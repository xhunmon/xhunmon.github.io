{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://qincji.gitee.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2020-12-07T23:59:33.704Z","updated":"2020-12-04T01:58:30.392Z","comments":false,"path":"/404.html","permalink":"http://qincji.gitee.io/404.html","excerpt":"","text":""},{"title":"标签","date":"2020-12-07T23:59:33.703Z","updated":"2020-12-04T01:58:30.394Z","comments":false,"path":"tags/index.html","permalink":"http://qincji.gitee.io/tags/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2020-12-07T23:59:33.648Z","updated":"2020-12-04T01:58:30.393Z","comments":false,"path":"repository/index.html","permalink":"http://qincji.gitee.io/repository/index.html","excerpt":"","text":""},{"title":"交个朋友呗~","date":"2020-12-08T09:54:18.797Z","updated":"2020-12-08T09:54:18.797Z","comments":true,"path":"links/index.html","permalink":"http://qincji.gitee.io/links/index.html","excerpt":"","text":""},{"title":"关于","date":"2020-12-07T23:59:33.679Z","updated":"2020-12-04T09:23:52.116Z","comments":false,"path":"about/index.html","permalink":"http://qincji.gitee.io/about/index.html","excerpt":"","text":"毕业至今已有4载有余，一直耕耘于Android以及NDK领域。而起于兴趣向往音视频领域发展，也已有一年有多。音视频领域犹如瀚海宇宙，我怒向翱翔之中。 1234567891011121314151617181920&#123; name: &#x27;秦城季&#x27; age: 29, gender: &#x27;男&#x27;, profession: &#x27;Android &amp; 音视频&#x27;, experience: &#x27;4年+&#x27;, address: &#x27;广东省广州市&#x27;, education: &#x27;本科&#x27;, github: &#x27;https://github.com/xhunmon&#x27;, blog: &#x27;https://xhunmon.github.io&#x27;, csdn: &#x27;https://blog.csdn.net/github_38117599&#x27; email: &#x27;xhunmon@126.com&#x27;, description: &#x27;致力于Android与音视频领域&#x27;, skills: [ [&#x27;Java&#x27;, &#x27;Dart&#x27;, &#x27;Jni&#x27;,&#x27;C++&#x27;, &#x27;Shell&#x27;], [&#x27;Git&#x27;, &#x27;SVN&#x27;], [&#x27;音视频&#x27;] ]&#125; 用代码谱写的青春绽放出了炫丽的新时代 ——向每一个位码农致敬~ ​"},{"title":"","date":"2020-12-08T09:31:40.699Z","updated":"2020-12-08T09:31:40.699Z","comments":false,"path":"life/index.html","permalink":"http://qincji.gitee.io/life/index.html","excerpt":"","text":"只言片语导航 &nbsp;- 不懂就搜，一搜就懂 var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?786a6208323fbecfb41d71bfda8daca6\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); 只言片语，可寻万物 x 谷歌 百度 必应 360搜索 搜狗 网盘搜索 史级珍藏 大力盘搜索 今日热榜 虫部落 阿虚同学 地图搜租房 SoBooks Chrome插件 阿里矢量图 爱给网 娱乐 vip视频解析 阳光电影 电影FM 小霸王 看片狂人 蛋蛋赞影院 果汁排行榜 动漫之家 蓝光网 献给祖国的花朵 twinkl教学资源 全历史 古诗文 国学大师 金榜题名 电子报刊 名人名言 对对联 MBA智库 效率之王 手机破解软件 Kindle工具 教育工具总结 精品Mac应用 威风-果粉 谷歌镜像 在线刷流量 电子书共享 在线pdf转换 程序员幸福之星 程序员工具箱 谷歌开发者 在线工具库 开源中国 私活平台汇总 前端工具 LeetCode算法 安卓开源汇总 程序员导航 有趣的偏门知识 探月工程数据 动物图鉴 医学信息 中国色 中国哲学书 养蜜蜂 中国生物名录 中国古今妖怪 云游中国"},{"title":"","date":"2020-12-07T23:59:33.695Z","updated":"2020-12-06T08:45:45.764Z","comments":true,"path":"life/static/css/style.css","permalink":"http://qincji.gitee.io/life/static/css/style.css","excerpt":"","text":"/* ================ reset 样式 start ================ */ * { margin: 0; padding: 0; font-family: \"微软雅黑\"; -webkit-box-sizing: border-box; -moz-box-sizing: border-box; box-sizing: border-box; } body, ul, li, h1, h2, h3, h4, h5, h6, p, form, dl, dt, dd { margin: 0px; padding: 0px; font-size: 14px; font-weight: normal; } img { border-style: none; } li { list-style: none; } a { text-decoration: none } html, body { background: #fff; height: 100%; } input[type=\"button\"], input[type=\"submit\"], input[type=\"reset\"] { -webkit-appearance: none; outline: 0; } textarea { -webkit-appearance: none; } /* ================ reset 样式 end ================ */ .inner-center { width: 1000px; margin: 0 auto; } .main { padding-top: 1%; min-height: 100%; right: 2%; float: right; width: 300px; } .content-inside{ padding-bottom: 60px; } .footer { height: 60px; text-align: center; margin-top: -60px; /* position: relative; margin-top: -100px; clear:both; */ } /* logo start */ .logo-box { display: flex; overflow: hidden; margin-left: 250px; align-items: center; } .logo-left { position: relative; width: 125px; height: 121px; cursor: pointer; } .logo-right { padding-left: 36px; font-size: 36px; color: rgba(0, 39, 102, 1); font-family: SourceHanSansSC-regular; } /* logo end */ /* 搜索框 start */ .search-section { margin-top: 14px; margin-bottom: 40px; } .search-section { position: relative; display: flex; } .search-left { display: flex; width: 877px; height: 54px; line-height: 20px; border: 1px solid rgba(217, 217, 217, 0.96); } .search-logo { width: 40px; align-items: center; justify-content: center; background: url(\"./img/scgoogle.png\") center center no-repeat; filter: grayscale(100%); -webkit-filter: grayscale(100%); -moz-filter: grayscale(100%); -o-filter: grayscale(100%); filter: alpha(opacity=20); -moz-opacity: 0.2; -khtml-opacity: 0.2; opacity: 0.2; cursor: pointer; } .search-logo:hover { filter: grayscale(0%); -webkit-filter: grayscale(0%); -moz-filter: grayscale(0%); -o-filter: grayscale(0%); filter: alpha(opacity=100); -moz-opacity: 1; -khtml-opacity: 1; opacity: 1; } .search-methods { display: none; position: absolute; left: 0; top: 54px; width: 155px; border: 1px solid rgba(217, 217, 217, 0.96); background-color: #fff; } .search-methods li { padding-left: 39px; background: url(\"./img/scgoogle.png\") 10px no-repeat; overflow: hidden; height: 34px; line-height: 34px; color: #545454; cursor: pointer; } .search-logo.baidu, li.baidu { background-image: url(\"./img/scbaidu.png\"); } .search-logo.bing, li.bing { background-image: url(\"./img/scbing.png\"); } .search-logo.sogou, li.sogou { background-image: url(\"./img/scsogou.png\"); } .search-logo.wangpan, li.wangpan { background-image: url(\"./img/scwangpan.png\"); } .search-logo.so, li.so { background-image: url(\"./img/scso.png\"); } .search-logo.google, li.google { background-image: url(\"./img/scgoogle.png\"); } .search-methods .search-item:hover { background-color: #f0f0f0; } .search-result { display: none; position: absolute; width: 837px; top: 55px; left: 40px; border: 1px solid rgba(187, 187, 187, 1); background-color: #fff; } .result-item { height: 34px; line-height: 34px; padding-left: 15px; } .result-item.active { background: #F0F0F0; } .result-item:hover { background-color: #eee; cursor: pointer; } .input-wrap { position: relative; flex: 1; } .input-wrap .search-input { height: 52px; width: 100%; outline: 0; border: 0; font-size: 16px; padding-left: 15px; } /* .input-wrap .search-input:focus{ border-style:solid; border-color: #FDA31E 96%; box-shadow: 0 0 10px #FDA31E; } */ /* .search-left:focus{ border-style:solid; border-color: #FDA31E 96%; box-shadow: 0 0 10px #FDA31E; } */ .input-wrap .clear-keyword { display: none; position: absolute; top: 50%; right: 10px; transform: translateY(-50%); cursor: pointer; color: #d2d2d2; font-size: 30px; } .search-submit { width: 123px; height: 54px; line-height: 26px; /* background: url(\"./img/search.png\") #1890ff 48px center no-repeat; */ background-color: #279fb5; /* background-image: url(\"./img/search.png\"); background-size: 48px; */ background-repeat: no-repeat; background-position: center; -webkit-background-size: 35px 35px; background-size: 35px 35px; color: #fff; font-size: 18px; font-weight: 500; text-align: center; font-family: Roboto; border: 1px solid #1890ff; cursor: pointer; background: linear-gradient(90deg, #87b6e2, #0b9be9); } /* 搜索框 end */ /* 导航内容 start */ .nav-content { overflow: hidden; } /* 导航内容 end */ /*内容区域*/ /*-----------------------------简洁版样式定义- 开始---------------------------------------------------*/ .jj-list { width: 33.33%; float: left; margin-bottom: 30px; padding-right: 16px; } .jj-list:nth-of-type(3n) { padding-right: 0; } .jj-list-tit { font-size: 16px; line-height: 25px; color: rgba(49, 70, 89, 1); font-weight: bold; } .jj-list-con { overflow: hidden; margin: 0 auto; } .jj-list-con li { box-sizing: border-box; /*以IE盒子模型的width为标准*/ padding: 1px 1px; /*设置div的内边距*/ width: 33.33%; /*div等分成4部分*/ float: left; transform-origin: center top; } .jj-list-con li:hover { animation: swing 2s linear 0s 1 forwards } @keyframes swing { 0%, 100% { transform: perspective(200px) rotateX(0); } 20% { transform: perspective(200px) rotateX(-45deg); } 40% { transform: perspective(200px) rotateX(45deg); } 50% { transform: perspective(200px) rotateX(-25deg); } 60% { transform: perspective(200px) rotateX(25deg); } 70% { transform: perspective(200px) rotateX(-5deg); } 80% { transform: perspective(200px) rotateX(5deg); } 90% { transform: perspective(200px) rotateX(-3deg); } 95% { transform: perspective(200px) rotateX(3deg); } } .jj-list-link { display: block; background: rgba(230, 247, 255, 0.96); color:rgba(49, 70, 89, 1); font-size: 10px; text-align: center; line-height: 44px; transition: all 0.2s; border-radius: 2px; } .jj-list-link:hover { background: #1890ff 100%; font-size: 10px; font-weight: bold; color: #fff; } /*-----------------------------简洁版样式定义- 结束---------------------------------------------------*/"},{"title":"","date":"2020-12-07T23:59:33.697Z","updated":"2020-07-19T12:19:50.000Z","comments":true,"path":"life/static/js/keyword.js","permalink":"http://qincji.gitee.io/life/static/js/keyword.js","excerpt":"","text":"$(function () { // 默认搜索引擎记录 var searchTypeStore = { set: function (type) { localStorage.setItem('SearchType', type); }, get: function () { return localStorage.getItem('SearchType') || 'baidu'; }, }; var $searchMethods = $('#search_methods'); var $searchLogo = $('#search_logo'); var initSearchType = searchTypeStore.get(); $searchLogo.addClass(initSearchType).data('type', initSearchType); var search_types = [ { url: 'https://www.baidu.com/s?wd=', type: 'baidu' }, { url: 'https://www.sogou.com/web?query=', type: 'sogou' }, { url: 'https://cn.bing.com/search?q=', type: 'bing' }, { url: 'https://www.so.com/s?q=', type: 'so' }, { url: 'https://www.google.com/search?q=', type: 'google' }, { url: 'http://www.cilimao.cc/search?word=', type: 'cili' }, { url: 'http://neets.cc/search?key=', type: 'yingyin' }, { url: 'http://www.panduoduo.net/s/name/', type: 'wangpan' }, ]; $searchLogo.on('click', function () { $searchMethods.show(); }); // 搜索引擎切换 $searchMethods.on('click', 'li', function () { var type = $(this).data('type'); searchTypeStore.set(type); $searchLogo.removeClass() .data('type', type) .addClass(type + ' search-logo'); $searchMethods.hide(); $('#search_keyword').focus(); }); $searchMethods.on('mouseleave', function () { $searchMethods.hide(); }); var EVENT_CLEAR_KEYWORD = 'clearKeyword'; var EVENT_SEARCH = 'search'; // 关键词搜索输入 $('#search_keyword').on('keyup', function (event) { var keyword = $(this).val(); if(event.which==13){ if($('#search_result .active').length>0){ keyword = $('#search_result .active').eq(0).text(); } openSearch(keyword) return; } // TODO 上下键选择待选答案 var bl = moveChange(event); if(bl){ keywordChange(keyword); } }).on('blur', function () { // 推荐结果跳转 $('#search_result').on('click', 'li', function () { var word = $(this).text(); $('#search_keyword').val(word); openSearch(word); $('#search_result').hide(); }); // 解决失焦和点击事件冲突问题 setTimeout(function() { $('#search_result').hide(); }, 100) }).on('focus', function () { var keyword = $(this).val(); keywordChange(keyword); }); function moveChange(e){ var k = e.keyCode || e.which; var bl = true; switch(k){ case 38: rowMove('top'); bl = false; break; case 40: rowMove('down'); bl = false; break; } return bl; } function rowMove(move){ var search_result = $('#search_result'); var hove_li = null; search_result.find('.result-item').each(function(){ if($(this).hasClass('active')){ hove_li = $(this).index(); } }); if(move == 'top'){ if(hove_li==null){ hove_li = search_result.find('.result-item').length-1; }else{ hove_li--; } }else if(move == 'down'){ if(hove_li==null){ hove_li = 0; }else{ hove_li==search_result.find('.result-item').length-1?(hove_li=0):(hove_li++); } } search_result.find('.active').removeClass('active'); search_result.find('.result-item').eq(hove_li).addClass('active'); $('#search_keyword').val(search_result.find('.result-item').eq(hove_li).addClass('active').text()); } function keywordChange(keyword) { if (keyword === '') { $(document).trigger(EVENT_CLEAR_KEYWORD); } else { $(document).trigger(EVENT_SEARCH, keyword); $('#clear_keyword').show(); } } // 清空输入框 $('#clear_keyword').on('click', function () { $('#search_keyword').val(''); $('#search_keyword').focus(); $(document).trigger(EVENT_CLEAR_KEYWORD); }); // 点击高亮显示 $('#search_keyword').on('focus', function () { $('.search-left').css( { \"border-style\":\"solid\", \"border-color\": \"rgba(24, 144, 255, 1)\", \"box-shadow\": \"0px 0px 2px 1px rgba(145, 213, 255, 0.96)\", } ); }).on('blur', function () { $('.search-left').prop('style',''); }); // 搜索 $('#search_submit').on('click', function () { var keyword = $('#search_keyword').val(); var type = getSeachType(); var baseUrl = search_types.find(function (item) { return item.type === type; }); if (baseUrl && keyword) { window.open(baseUrl.url + keyword); } }); $(document).on(EVENT_CLEAR_KEYWORD, function () { $('#clear_keyword').hide(); $('#search_result').hide(); }); $(document).on(EVENT_SEARCH, function (e, keyword) { getSearchResult(keyword); }); // 获取搜索引擎类型 function getSeachType() { return $('#search_logo').data('type'); } // google 搜索结果 function searchResultGoogle(data) { var result = data[1]; result = result.map(function (item) { return item[0]; }); renderSearchResult(result); } // 百度 搜索结果 function searchResultBaidu(data) { if (data === undefined) { return; } var result = data.s; renderSearchResult(result); } // 渲染搜索结果 function renderSearchResult(array) { var $result = $('#search_result'); $result.empty().hide(); if (!array || array.length"},{"title":"","date":"2020-12-07T23:59:33.696Z","updated":"2020-07-19T12:19:50.000Z","comments":true,"path":"life/static/js/jquery.min.js","permalink":"http://qincji.gitee.io/life/static/js/jquery.min.js","excerpt":"","text":"/*! jQuery v3.3.0 | (c) JS Foundation and other contributors | jquery.org/license */ !function(e,t){\"use strict\";\"object\"==typeof module&&\"object\"==typeof module.exports?module.exports=e.document?t(e,!0):function(e){if(!e.document)throw new Error(\"jQuery requires a window with a document\");return t(e)}:t(e)}(\"undefined\"!=typeof window?window:this,function(e,t){\"use strict\";var n=[],r=e.document,i=Object.getPrototypeOf,o=n.slice,a=n.concat,s=n.push,u=n.indexOf,l={},c=l.toString,f=l.hasOwnProperty,p=f.toString,d=p.call(Object),h={},g=function e(t){return\"function\"==typeof t&&\"number\"!=typeof t.nodeType},y=function e(t){return null!=t&&t===t.window},v={type:!0,src:!0,noModule:!0};function m(e,t,n){var i,o=(t=t||r).createElement(\"script\");if(o.text=e,n)for(i in v)n[i]&&(o[i]=n[i]);t.head.appendChild(o).parentNode.removeChild(o)}function x(e){return null==e?e+\"\":\"object\"==typeof e||\"function\"==typeof e?l[c.call(e)]||\"object\":typeof e}var b=\"3.3.0\",w=function(e,t){return new w.fn.init(e,t)},T=/^[\\s\\uFEFF\\xA0]+|[\\s\\uFEFF\\xA0]+$/g;w.fn=w.prototype={jquery:\"3.3.0\",constructor:w,length:0,toArray:function(){return o.call(this)},get:function(e){return null==e?o.call(this):e1?(n=[e,e,\"\",t],r.setFilters.hasOwnProperty(e.toLowerCase())?se(function(e,n){var r,o=i(e,t),a=o.length;while(a--)e[r=O(e,o[a])]=!(n[r]=o[a])}):function(e){return i(e,0,n)}):i}},pseudos:{not:se(function(e){var t=[],n=[],r=s(e.replace(B,\"$1\"));return r[b]?se(function(e,t,n,i){var o,a=r(e,null,i,[]),s=e.length;while(s--)(o=a[s])&&(e[s]=!(t[s]=o))}):function(e,i,o){return t[0]=e,r(t,null,o,n),t[0]=null,!n.pop()}}),has:se(function(e){return function(t){return oe(e,t).length>0}}),contains:se(function(e){return e=e.replace(Z,ee),function(t){return(t.textContent||t.innerText||i(t)).indexOf(e)>-1}}),lang:se(function(e){return U.test(e||\"\")||oe.error(\"unsupported lang: \"+e),e=e.replace(Z,ee).toLowerCase(),function(t){var n;do{if(n=g?t.lang:t.getAttribute(\"xml:lang\")||t.getAttribute(\"lang\"))return(n=n.toLowerCase())===e||0===n.indexOf(e+\"-\")}while((t=t.parentNode)&&1===t.nodeType);return!1}}),target:function(t){var n=e.location&&e.location.hash;return n&&n.slice(1)===t.id},root:function(e){return e===h},focus:function(e){return e===d.activeElement&&(!d.hasFocus||d.hasFocus())&&!!(e.type||e.href||~e.tabIndex)},enabled:de(!1),disabled:de(!0),checked:function(e){var t=e.nodeName.toLowerCase();return\"input\"===t&&!!e.checked||\"option\"===t&&!!e.selected},selected:function(e){return e.parentNode&&e.parentNode.selectedIndex,!0===e.selected},empty:function(e){for(e=e.firstChild;e;e=e.nextSibling)if(e.nodeType=3?[null,e,null]:L.exec(e))||!i[1]&&t)return!t||t.jquery?(t||n).find(e):this.constructor(t).find(e);if(i[1]){if(t=t instanceof w?t[0]:t,w.merge(this,w.parseHTML(i[1],t&&t.nodeType?t.ownerDocument||t:r,!0)),A.test(i[1])&&w.isPlainObject(t))for(i in t)g(this[i])?this[i](t[i]):this.attr(i,t[i]);return this}return(o=r.getElementById(i[2]))&&(this[0]=o,this.length=1),this}return e.nodeType?(this[0]=e,this.length=1,this):g(e)?void 0!==n.ready?n.ready(e):e(w):w.makeArray(e,this)}).prototype=w.fn,q=w(r);var H=/^(?:parents|prev(?:Until|All))/,O={children:!0,contents:!0,next:!0,prev:!0};w.fn.extend({has:function(e){var t=w(e,this),n=t.length;return this.filter(function(){for(var e=0;e1&&(O[e]||w.uniqueSort(i),H.test(e)&&i.reverse()),this.pushStack(i)}});var M=/[^\\x20\\t\\r\\n\\f]+/g;function R(e){var t={};return w.each(e.match(M)||[],function(e,n){t[n]=!0}),t}w.Callbacks=function(e){e=\"string\"==typeof e?R(e):w.extend({},e);var t,n,r,i,o=[],a=[],s=-1,u=function(){for(i=i||e.once,r=t=!0;a.length;s=-1){n=a.shift();while(++s-1)o.splice(n,1),n-1:o.length>0},empty:function(){return o&&(o=[]),this},disable:function(){return i=a=[],o=n=\"\",this},disabled:function(){return!o},lock:function(){return i=a=[],n||t||(o=n=\"\"),this},locked:function(){return!!i},fireWith:function(e,n){return i||(n=[e,(n=n||[]).slice?n.slice():n],a.push(n),t||u()),this},fire:function(){return l.fireWith(this,arguments),this},fired:function(){return!!r}};return l};function I(e){return e}function W(e){throw e}function $(e,t,n,r){var i;try{e&&g(i=e.promise)?i.call(e).done(t).fail(n):e&&g(i=e.then)?i.call(e,t,n):t.apply(void 0,[e].slice(r))}catch(e){n.apply(void 0,[e])}}w.extend({Deferred:function(t){var n=[[\"notify\",\"progress\",w.Callbacks(\"memory\"),w.Callbacks(\"memory\"),2],[\"resolve\",\"done\",w.Callbacks(\"once memory\"),w.Callbacks(\"once memory\"),0,\"resolved\"],[\"reject\",\"fail\",w.Callbacks(\"once memory\"),w.Callbacks(\"once memory\"),1,\"rejected\"]],r=\"pending\",i={state:function(){return r},always:function(){return o.done(arguments).fail(arguments),this},\"catch\":function(e){return i.then(null,e)},pipe:function(){var e=arguments;return w.Deferred(function(t){w.each(n,function(n,r){var i=g(e[r[4]])&&e[r[4]];o[r[1]](function(){var e=i&&i.apply(this,arguments);e&&g(e.promise)?e.promise().progress(t.notify).done(t.resolve).fail(t.reject):t[r[0]+\"With\"](this,i?[e]:arguments)})}),e=null}).promise()},then:function(t,r,i){var o=0;function a(t,n,r,i){return function(){var s=this,u=arguments,l=function(){var e,l;if(!(t=o&&(r!==W&&(s=void 0,u=[e]),n.rejectWith(s,u))}};t?c():(w.Deferred.getStackHook&&(c.stackTrace=w.Deferred.getStackHook()),e.setTimeout(c))}}return w.Deferred(function(e){n[0][3].add(a(0,e,g(i)?i:I,e.notifyWith)),n[1][3].add(a(0,e,g(t)?t:I)),n[2][3].add(a(0,e,g(r)?r:W))}).promise()},promise:function(e){return null!=e?w.extend(e,i):i}},o={};return w.each(n,function(e,t){var a=t[2],s=t[5];i[t[1]]=a.add,s&&a.add(function(){r=s},n[3-e][2].disable,n[3-e][3].disable,n[0][2].lock,n[0][3].lock),a.add(t[3].fire),o[t[0]]=function(){return o[t[0]+\"With\"](this===o?void 0:this,arguments),this},o[t[0]+\"With\"]=a.fireWith}),i.promise(o),t&&t.call(o,o),o},when:function(e){var t=arguments.length,n=t,r=Array(n),i=o.call(arguments),a=w.Deferred(),s=function(e){return function(n){r[e]=this,i[e]=arguments.length>1?o.call(arguments):n,--t||a.resolveWith(r,i)}};if(t0||F.resolveWith(r,[w]))}}),w.ready.then=F.then;function _(){r.removeEventListener(\"DOMContentLoaded\",_),e.removeEventListener(\"load\",_),w.ready()}\"complete\"===r.readyState||\"loading\"!==r.readyState&&!r.documentElement.doScroll?e.setTimeout(w.ready):(r.addEventListener(\"DOMContentLoaded\",_),e.addEventListener(\"load\",_));var z=function(e,t,n,r,i,o,a){var s=0,u=e.length,l=null==n;if(\"object\"===x(n)){i=!0;for(s in n)z(e,t,s,n[s],!0,o,a)}else if(void 0!==r&&(i=!0,g(r)||(a=!0),l&&(a?(t.call(e,r),t=null):(l=t,t=function(e,t,n){return l.call(w(e),n)})),t))for(;s1,null,!0)},removeData:function(e){return this.each(function(){K.remove(this,e)})}}),w.extend({queue:function(e,t,n){var r;if(e)return t=(t||\"fx\")+\"queue\",r=J.get(e,t),n&&(!r||Array.isArray(n)?r=J.access(e,t,w.makeArray(n)):r.push(n)),r||[]},dequeue:function(e,t){t=t||\"fx\";var n=w.queue(e,t),r=n.length,i=n.shift(),o=w._queueHooks(e,t),a=function(){w.dequeue(e,t)};\"inprogress\"===i&&(i=n.shift(),r--),i&&(\"fx\"===t&&n.unshift(\"inprogress\"),delete o.stop,i.call(e,a,o)),!r&&o&&o.empty.fire()},_queueHooks:function(e,t){var n=t+\"queueHooks\";return J.get(e,n)||J.access(e,n,{empty:w.Callbacks(\"once memory\").add(function(){J.remove(e,[t+\"queue\",n])})})}}),w.fn.extend({queue:function(e,t){var n=2;return\"string\"!=typeof e&&(t=e,e=\"fx\",n--),arguments.length"}],"posts":[{"title":"编译ffmpeg4.2.2","slug":"ffmpeg/03_build_ffmpeg","date":"2020-12-17T05:30:35.000Z","updated":"2020-12-17T09:03:19.983Z","comments":true,"path":"2020/12/17/ffmpeg/03_build_ffmpeg/","link":"","permalink":"http://qincji.gitee.io/2020/12/17/ffmpeg/03_build_ffmpeg/","excerpt":"","text":"前言 在编译FFmpeg之前，我们得先知道FFmpeg包含了那些内容（组件），我们应该要如何查看并选择？这里我们就简单来说说FFmpeg编译的过程，以及集成x264，编译android平台所需要的动态库等。（这里的测试使用的是Mac系统） FFmpeg编译流程 编译过程主要分为两步（下图）： (1)configure：通过configure --help查看我们所能选择的配置。前往查看configure配置选项注释。这一步后会生成许多Makefile编译所需要的东西。其中在 ffbuild/config.log 可查看当前执行的日志。 (2)make install：编译生成我们所配置的东西。如果之前编译过需要make clean清除之前编译过的数据再执行make install。 注：生成的执行文件或可移植类库时根据系统会不一样，比如生成ffplay时：Unix系统会是ffplay，windows会是ffplay.exe。 FFmpeg基本组成结构 从configure配置文件中阅读可知，FFmpeg基本组成结构可以下部分（下图）： 主要由AVCodec（编解码相关）、AVDevice（输入/输出设备相关）、AVFilter（滤波处理相关）和AVFormat（数据格式处理相关）四大基本模块构成。在这四大模块下又细分了一些小模块，这里对小模块作用简单做一下说明： bsfs：格式转换。通过./configure --list-bsfs查看所有能支持转换的格式。 decoders：解码器。通过./configure --list-decoders查看所有能支持解码器。 encoders：编码器。通过./configure --list-encoders查看所有能支持编码器。 hwaccels：硬件编解码器。通过./configure --list-hwaccels查看所有能支持硬件编解码器。 parsers：解析器。通过./configure --list-parsers查看所有能支持解析器。 indevs：输入设备（如安卓摄像头）。通过./configure --list-indevs查看所有能支持输入设备。 outdevs：输出设备（如opengl）。通过./configure --list-outdevs查看所有能支持输出设备。 filters：滤镜处理器（如gblur高斯模糊）。通过./configure --list-filters查看所有能支持滤镜处理器。 muxers：封装（如把flv容器格式视频拆解出视频流、音频流等）。通过./configure --list-muxers查看所有能支持封装。 demuxers：解封装（对应封装）。通过./configure --list-demuxers查看所有能支持解封装。 protocols：协议（如rtmp）。通过./configure --list-protocols查看所有能支持的协议。 选择模块进行编译 上面简单介绍了ffmpeg的编译流程以及ffmpeg库到底包含了那些类库。知道了这些，我们就可以选择我们所需要的类库进行编译了。如果默认编译出来的ffmpeg将会是相当庞大的，像一下动态库移植，库太大就很烦恼了。而且像x264库等一些第三方库也是需要知道如何进行配置的。这里我们的就探讨一下如何选择我们所需要的类库进行编译。 准备 (1)下载ffmpeg源文件 ，根据自己的系统进行选择，下载回来后进行解压。 (2)参考官方文档 ，如：Mac需要按照Xcode等，编译也应该先看官网文档介绍。（最靠谱的方式吧？） (3)掌握Shell基础知识 ，为了方便修改与编译。 (4)下载x264 ，《测试3》需要用。 (5)下载NDK ，注意系统的类型。《测试4》需要用。 测试1：仅仅编译出ffplay程序 configure配置文件中默认是输出所有程序的（ffmpeg、ffplay和ffprobe）。但是因为ffplay需要sdl2库，所以这里讲一下如何配置单单输出ffplay程序。 (1)安装sdl2 从configure配置文件中得知，ffplay程序需要依赖sdl2库。Mac可通过执行brew install sdl2命令进行安装。 (2)编译验证ffplay 在项目的根目录编写build.sh脚本文件并授权，如下。然后在控制台中直接执行./build.sh。 script123456#!/bin/bash./configure \\ --disable-programs \\ --enable-ffplaymake cleanmake install 然后在控制台中看到输出信息，发现只有ffplay程序将要被编译。 等待十几分钟后，我们发现在项目的根目录仅仅生成ffplay可执行文件，我们在控制台执行du -sh ./ffplay命令看看生成文件的大小有20M。 script12qincji:ffmpeg mac$ du -sh ./ffplay 20M ./ffplay 执行命令播放一个rtmp：./ffplay -window_title &quot;版本1&quot; rtmp://slive.ytn.co.kr/dmb/ydlive_20140419_1，结果如下： 好了，我们编译的ffplay播放器能正常使用了。使用./ffplay --help查看具体用法。 (3)查找这样配置的原因 上面我们已经知道了编译结果，这里需要找一下原因，这到底为何？我们从configure文件找到一些蛛丝马迹： script12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#略……………………#program队列PROGRAM_LIST=&quot; ffplay ffprobe ffmpeg&quot;#略……………………#disable方法，将调用set_all，并传值为no，以及将要设置disable的名称($*)。disable()&#123; set_all no $*&#125;#略……………………set_all()&#123; value=$1 shift for var in $*; do eval $var=$value done&#125;:&lt;&lt;EOF这里的opt其实就是我们输入的 --disable-programs 和 --enable-ffplay./configure \\ --disable-programs \\ --enable-ffplayEOFfor opt do optval=&quot;$&#123;opt#*=&#125;&quot; case &quot;$opt&quot; in #略…………………… #当我们配置了--disable-programs，就会命中这里，将PROGRAM_LIST列表里面的disable掉。 --disable-programs) disable $PROGRAM_LIST ;; #略…………………… #当我们配置了--enable-ffplay时，就会命中这里，将启用ffplay。这里语法不太熟悉，我们可以在这个地方中打印就下即可 *) optname=&quot;$&#123;opt%%=*&#125;&quot; optname=&quot;$&#123;optname#--&#125;&quot; optname=$(echo &quot;$optname&quot; | sed &#x27;s/-/_/g&#x27;) if is_in $optname $CMDLINE_SET; then eval $optname=&#x27;$optval&#x27; elif is_in $optname $CMDLINE_APPEND; then append $optname &quot;$optval&quot; else die_unknown $opt fi ;; esacdone#略…………………… 测试2：根据测试1中去掉支持rtmp协议 在测试1中我们是把程序模块的先全部取消编译，然后再选择其中一个。这里我们选择仅仅去掉一个模块中的单个组件。我们举一个例子，取消支持protocols中的rtmp协议： (1)如何入手？ 我们知道一切编译皆来自configure配置文件，所以我们得从这个文件找我们需要的信息。我刚开始找rtmp相关信息，只是找到librtmp库的启用或取消，然后编译了一下，发现并不是！ 然后我就搜索protocols，发现有一条关键信息，如下： script123456#单个组件配置Individual component options: #略………… #这就是我想要的！！后面NAME是rtmp！如何知道？通过 ./configure --list-protocols 看到所有支持协议的名称 --disable-protocol=NAME disable protocol NAME --disable-protocols disable all protocols (2)编译验证结果 修改build.sh脚本，如下。然后在控制台中直接执行./build.sh。 script1234567#!/bin/bash./configure \\ --disable-programs \\ --enable-ffplay \\ --disable-protocol=rtmpmake cleanmake install 然后在控制台中看到输出信息，发现Enabled protocols:中已经没有了rtmp协议了！ 等待编译完成，执行命令播放一个rtmp：./ffplay -window_title &quot;版本2&quot; rtmp://slive.ytn.co.kr/dmb/ydlive_20140419_1，结果如下： 开启或者禁用其他组件的道理也是一样哦。 测试3：集成第三方库：x264 ffmpeg官方mac编译指南集成libx264 ，但是给出的信息不是很明确（有些我不太懂），几经波折后发现，是需要指定CFLAGS和LDFLAGS（也就是--extra-cflags和--extra-ldflags）才编译通过的。这里给出编译脚本，在编写前我们把下载下来解压后的x264库改名为libx264然后放进ffmpeg项目根目录。修改build.sh脚本，如下。然后在控制台中直接执行./build.sh。 script123456789101112131415161718192021222324252627#!/bin/bashfunction build_x264() &#123; cd libx264 ./configure \\ --prefix=$&#123;X264_LIBS&#125; \\ --enable-static make clean make install&#125;function build_ffmpeg() &#123; cd .. ./configure \\ --disable-programs \\ --enable-ffmpeg \\ --enable-gpl \\ --extra-cflags=&quot;-I$&#123;X264_LIBS&#125;/include&quot; \\ --extra-ldflags=&quot;-L$&#123;X264_LIBS&#125;/lib&quot; \\ --enable-libx264 make clean make install&#125;#设置x264变成出来的静态库保存路径，然后编译ffmpeg时，链接进去X264_LIBS=$(pwd)/libx264/libouputbuild_x264build_ffmpeg 编译过程中，我们留意到控制台的到输出信息，发现libx264协议被启用了： 等待编译成功后，验证当前生成的ffmpeg程序是否已经集成了libx264，找个mp4视频放到当前目录，命名为input.mp4。然后执行以下命令，如果没报错说了已成功集成： ./ffmpeg -re -i input.mp4 -vcodec libx264 -an output.mp4 测试4：android交叉编译 ffmpeg官网android编译指南 ， 测试了一下，最后发现这几个参数比较关键： --enable-cross-compile : 开启交叉编译。 --cross-prefix : gcc的前缀。（如果使用clang编译则可以不给） --target-os : 指定android使用平台。 --arch : 处理器类型。 --cpu : cpu类型。 --cc : c语言编译器（给当前指定的绝对路径）。 --cxx : c++语言编译器（给当前指定的绝对路径）。 --extra-cflags : 给传递给编译器的参数。 修改build.sh脚本，如下。然后在控制台中直接执行./build.sh。 script1234567891011121314151617181920212223242526272829303132333435#!/bin/bashAPI=21export NDK=/Users/Qincji/Desktop/develop/android/source/sdk/ndk-bundleexport SYSROOT=$NDK/toolchains/llvm/prebuilt/linux-x86_64/sysrootexport TOOLCHAIN=$NDK/toolchains/llvm/prebuilt/darwin-x86_64function build_android() &#123; ./configure \\ --prefix=$PREFIX \\ --disable-programs \\ --disable-static \\ --enable-shared \\ --cross-prefix=$CROSS_PREFIX \\ --target-os=android \\ --arch=$ARCH \\ --cpu=$CPU \\ --cc=$CC \\ --cxx=$CXX \\ --enable-cross-compile \\ --extra-cflags=&quot;$CFLAG&quot; || exit 0 make clean make install&#125;ARCH=armCPU=armv7-aCC=$TOOLCHAIN/bin/armv7a-linux-androideabi$API-clangCXX=$TOOLCHAIN/bin/armv7a-linux-androideabi$API-clang++CROSS_PREFIX=$TOOLCHAIN/bin/arm-linux-androideabi-PREFIX=$(pwd)/android/$CPUOPTIMIZE_CFLAGS=&quot;-mfloat-abi=softfp -mfpu=vfp -marm -march=$CPU&quot;CFLAG=&quot;-Os -fpic $OPTIMIZE_CFLAGS&quot;build_android 等待编译完成，我们发现能成功编译出动态库： 总结 好了，ffmpeg编译已经基本讲述完了。这里总结一下我所编译过程的一些想法： 使用IDE管理项目，自己处理的方便就行。我这里用clion，github有破解方式。 configure 文件非常重要，shell语法还是要懂一点。 报错了注意查看日志ffbuild/config.log。 路径一定要看是否真实存在，如$CC可能在一些API版本上xxx-clang是没有的。 参考 https://blog.csdn.net/leixiaohua1020/article/details/44587465 https://blog.csdn.net/leixiaohua1020/article/details/44556525","categories":[],"tags":[{"name":"ffmpeg","slug":"ffmpeg","permalink":"http://qincji.gitee.io/tags/ffmpeg/"}]},{"title":"Shell脚本","slug":"ffmpeg/02_shell","date":"2020-12-13T06:30:35.000Z","updated":"2020-12-14T03:18:39.370Z","comments":true,"path":"2020/12/13/ffmpeg/02_shell/","link":"","permalink":"http://qincji.gitee.io/2020/12/13/ffmpeg/02_shell/","excerpt":"","text":"简介 Shell脚本（Shell Script）是一种为Shell编写的脚本程序。而Shell是一个用C语言编写的程序，它是用户使用Linux的桥梁。在Linux中Shell程序又有很多种，如： sh - 即 Bourne Shell。sh 是 Unix 标准默认的 shell。 bash - 即 Bourne Again Shell。bash 是 Linux 标准默认的 shell。 …… 其中，bash由于易用和免费，被广泛使用。每种Shell程序都有其对应的解释器，在脚本文件第一行会告诉系统当前程序属于那种类型，如： script12#!/bin/bashecho &quot;这是bash类型的shell程序&quot; 本文主要介绍bash类型的Shell脚本的基本使用。 Shell脚本权限 Shell脚本被执行前需要可执行权限。如刚创建的test.sh脚本，需chmod +x test.sh方能执行： script12345qincji:giteeblog mac$ ./test.sh-bash: ./test.sh: Permission deniedqincji:giteeblog mac$ chmod +x test.sh qincji:giteeblog mac$ ./test.sh Hellow Shell 注：执行脚本文件的命令使用sh或.，如sh test.sh或./test.sh。 Shell基本语法 注释 单行注释 - 以 # 开头，到行尾结束。 多行注释 - 以 :&lt;&lt;EOF 开头，到 EOF 结束。 如编辑test.sh脚本文件 script12345678#!/bin/bash echo &quot;Hellow Shell&quot;#echo &quot;使用#单行注释了，不能输出&quot; :&lt;&lt;EOFecho &quot;EOF里面111&quot;echo &quot;EOF里面222&quot; EOF 执行sh test.sh查看输出： script12qincji:giteeblog mac$ sh test.sh Hellow Shell echo输出 echo用于字符串的输出。编辑test.sh进行介绍： script12345678#!/bin/bash echo &quot;1-You&quot; #1.输出普通字符串echo &quot;2-You \\&quot;are\\&quot;&quot; #2.输出使用\\转义age=18echo &quot;3-You \\&quot;are\\&quot; $&#123;age&#125;&quot; #3.使用$&#123;变量名&#125;输出包含变量的字符串echo &quot;4-You \\&quot;are\\&quot; &quot;$age&quot;&quot; #4.使用&quot;$变量名&quot;输出包含变量的字符串&quot;echo -e &quot;5-YES\\nNO&quot; #5.使用 -e 开启（对\\n）转义echo &quot;6-test&quot; &gt; test.txt #6.输出重定向至文件 执行后输出结果： script123456789qincji:giteeblog mac$ ./test.sh 1-You2-You &quot;are&quot;3-You &quot;are&quot; 184-You &quot;are&quot; 185-YESNOqincji:giteeblog mac$ cat test.txt6-test 变量 Bash 中没有数据类型，bash 中的变量可以保存一个数字、一个字符、一个字符串等等。定义变量名的规则： 1.命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。 2.中间不能有空格，可以使用下划线（_）。 3.不能使用标点符号。 4.不能使用 bash 里的关键字（可用 help 命令查看保留关键字）。 如，编辑test.sh如下： script123456789101112131415161718#!/bin/bash#有效变量名var=&quot;0 字符串&quot;VAR=1_var=2_var2=3_3var=4#以下为无效变量名4var=5?var=6var*2=7#使用表达式命令赋值，输出看看命令的结果files=`du -sh .`echo $&#123;files&#125;#删除变量unset varecho $&#123;var&#125; 执行输出结果： script12345qincji:giteeblog mac$ ./test.sh ./test.sh: line 9: 4var=5: command not found./test.sh: line 10: ?var=6: command not found./test.sh: line 11: var*2=7: command not found138M . 字符串 使用'或者&quot;来定义字符串，也可以不用引号。但是'中不能使用变量和转义符。所以记住用&quot;就行了。字符串常规操作，有： 1.字符串拼接，格式：'hello，'$&#123;串&#125;''或&quot;hello，$&#123;串&#125;&quot;。 2.获取字符串长度，格式：$&#123;#串&#125;。 3.截取字符串，格式$&#123;串:2:3&#125;，其中2为起点，3为截取的个数。 编辑test.sh如下： script12345678#!/bin/bashname=&quot;123456&quot;full1=&#x27;1-hello，&#x27;$&#123;name&#125;&#x27;&#x27; #1.单引号字符串拼接full2=&quot;1-hello，$&#123;name&#125;&quot; #1.双引号字符串拼接echo $&#123;full1&#125;echo $&#123;full2&#125;echo &quot;2-长度：$&#123;#name&#125;&quot; #2.获取字符串长度echo &quot;3-截取：$&#123;name:2:3&#125;&quot; #3.截取字符串 执行输出结果： script12345qincji:giteeblog mac$ ./test.sh 1-hello，1234561-hello，1234562-长度：63-截取：345 数组 Bash只支持一维数组，下标从 0 开始，下标可以是整数或算术表达式，其值应大于或等于 0。数组常规操作，有： 1.创建数组，格式：array=(value0 value1 value2)或指定下标array=([1]=value0 [1]=value1 [2]=value2)。 2.访问元素，格式：获取单个：&quot;$&#123;array[下标]&#125;&quot;；获取所有：&quot;$&#123;array[@]&#125;&quot;。 3.取得个数，格式：&quot;$&#123;#array[@]&#125;&quot;或&quot;$&#123;#array[*]&#125;&quot;。 4.增加元素，格式：array=(value3 &quot;$&#123;array[@]&#125;&quot; value4)。 5.删除元素，格式：unset array[0]。 编辑test.sh如下： script12345678#!/bin/basharray=([1]=1 [0]=&quot;a&quot; [3]=&quot;￥&quot;) #1.创建数组echo &quot;2-访问：v1=$&#123;array[1]&#125;，v2=$&#123;array[@]&#125;&quot; #2.访问元素echo &quot;3-获取：len1=$&#123;#array[@]&#125;，len2=$&#123;#array[*]&#125;&quot; #3.取得个数array=(&quot;NO&quot; &quot;$&#123;array[@]&#125;&quot; 33) #4.增加元素echo &quot;4-增加：$&#123;array[@]&#125;&quot;unset array[0] #5.删除元素echo &quot;5-删除：$&#123;array[@]&#125;&quot; 执行输出结果： script12345qincji:giteeblog mac$ ./test.sh 2-访问：v1=1，v2=a 1 ￥3-获取：len1=3，len2=34-增加：NO a 1 ￥ 335-删除：a 1 ￥ 33 运算符 算术运算符 + - * / %（加减乘除取余），格式：expr value0 符号 value1，特殊符号需要转义，如expr 3 \\* 4结果为12。 =（赋值），格式：value=value1，把value1赋值给value。 ==（比较相等），格式：[ value1 == value2 ]，如[ 2 == 5 ]，返回false。 !=（比较不相等），格式：[ value1 != value2 ]，如[ 2 != 5 ]，返回true。 注意：[ value1 != 'value2' ]是带空格的，如错误写法：[value1!='value2']。在循环体测试中使用[]不起作用，需要用(())，如： script1234567891011121314a=1while (($a &lt; 10)); do# if [ a == 2 ] #不起作用 if ((a == 2)); then echo &quot;while语句：continue&quot; let &quot;a++&quot; continue elif ((a == 4)); then echo &quot;while语句：break&quot; break fi echo &quot;while语句：$a&quot; let &quot;a++&quot;done 编辑test.sh如下： script1234567891011#!/bin/basha=3b=3o1=`expr $&#123;a&#125; \\* $&#123;b&#125;`echo &quot;o1=$&#123;o1&#125;&quot;if [ $a == $b ]then echo &quot;a 等于 b&quot;else echo &quot;a 不等于 b&quot;fi 执行输出结果： script123qincji:giteeblog mac$ ./test.sh o1=9a 等于 b 关系运算符 通用格式为：[ value1 符号 value2 ]，用于比较结构中，同上==和!=用法一样。 -eq 是否相等，格式：[ value1 -eq value2 ]，如[ 2 -eq 5 ]，返回false。 -ne 是否不相等，格式：同上。 -gt &gt;，格式：同上。 -lt &lt;，格式：同上。 -ge &gt;=，格式：同上。 -le &lt;=，格式：同上。 布尔运算符 ! 非，格式：[ ! 表达式 ]。与表示式结果相反。。如[ ! 1 == 1 ]返回 false。 -o 或 (与逻辑运算符||相同)，格式：[ 表达式1 -o 表达式2 ]。有一个表达式为 true 则返回 true。如[ 1 == 1 -o 2 != 2 ]返回 true。 -a 与 (与逻辑运算符&amp;&amp;相同)，格式：[ 表达式1 -o 表达式2 ]。两个表达式都为 true 才返回 true。如[ 1 == 1 -a 2 != 2 ]返回 false。 逻辑运算符 ||和&amp;&amp;参考布尔运算符。 字符串运算符 = 字符串相等，格式：[ value1 = value2 ]，如a=“a”,b=“b”，[ $&#123;a&#125; = $&#123;b&#125; ]，返回true。 != 字符串不相等，格式：[ value1 != value2 ]，如a=“a”,b=“b”，[ $&#123;a&#125; != $&#123;b&#125; ]，返回false。 -z 字符串长度为0为true，格式：[ -z value ]，如a=“a”，[ -z $&#123;a&#125; ]，返回false。 -n 字符串长度不为0为true， 格式：[ -n = value ]，如a=“a”，[ -n = $&#123;a&#125; ]，返回true。 文件运算符 通用格式为：[符号 文件路径 ]，用于检查文件的属性，如何符合为true。 -d 目录存在为true，格式：[ -d filePath ]，如[ -d &quot;./&quot; ]，为true。 -f 文件存在为true，格式：[ -f filePath ]，如[ -f &quot;./test.sh&quot; ]，为true。 -r 可读为true，格式：同上。 -w 可写为true，格式：同上。 -x 可执行 可执行为true，格式：同上。 -s 文件不为空(有内容) true，格式：同上。 -e 文件/目录存在，格式：同上。 编辑test.sh如下： script12345678910111213#!/bin/bashif [ -d &quot;./&quot; ]then echo &quot;1-输出为true&quot;else echo &quot;1-输出为false&quot;fiif [ -w &quot;./test.sh&quot; ]then echo &quot;2-输出为true&quot;else echo &quot;2-输出为false&quot;fi 执行输出结果： script123qincji:giteeblog mac$ ./test.sh 1-输出为true2-输出为true 流程控制 条件语句： ①if..elif..else，使用then..fi来控制命中的范围。单行格式：if [ 条件1 ]; then 执行体1; elif [ 条件2 ]; then 执行体2; else 执行体2; fi，多行格式：直接;去掉即可。 ②case，在exec..esac范围内。格式如下 script123456execcase 输入 in条件1) 执行体1;;条件2) 执行体2;;*) 其他执行体;;esac 循环语句：for、while和until。循环体在do..done范围内，在循环中遇到continue会进入下个循环，遇到break跳出循环。 编辑test.sh如下： script123456789101112131415161718192021222324252627282930313233343536373839404142434445#!/bin/bash#1.注意单行的写法需要用 ； 把语句段落隔开if [ &quot;111&quot; = &quot;abc&quot; ]; then echo &quot;输出if-1&quot;elif [ &quot;abc&quot; = &quot;abc&quot; ]; then echo &quot;输出elif-1&quot;else echo &quot;输出else-1&quot;fi#2.注意单行的写法需要用 ； 把语句段落隔开if [ &quot;111&quot; = &quot;abc&quot; ]; then echo &quot;输出if-2&quot;; elif [ &quot;abc2&quot; = &quot;abc&quot; ]; then echo &quot;输出elif-2&quot;; else echo &quot;输出else-2&quot;; fi#3.case语句execcase &quot;4&quot; in&quot;a&quot;) echo &quot;case输出a&quot; ;;&quot;b&quot;) echo &quot;case输出b&quot; ;;*) echo &quot;case输出*&quot; ;;esac#4.for语句for var in &quot;red&quot; 2 &quot;yes&quot;; do echo &quot;for语句：$&#123;var&#125;&quot;; done#5.while语句a=1#while [ $a -le 10 ]while (($a &lt; 10)); do # if [ a == 2 ] #不起作用 if ((a == 2)); then echo &quot;while语句：continue&quot; let &quot;a++&quot; continue elif ((a == 4)); then echo &quot;while语句：break&quot; break fi echo &quot;while语句：$a&quot; let &quot;a++&quot;done#6.until语句until (($a &gt;= 6)); do echo &quot;until语句：$a&quot; let &quot;a++&quot;done 执行输出结果： script12345678910111213qincji:giteeblog mac$ ./test.sh 输出elif-1输出else-2case输出*for语句：redfor语句：2for语句：yeswhile语句：1while语句：continuewhile语句：3while语句：breakuntil语句：4until语句：5 函数 编辑test.sh如下： script12345678#!/bin/bash#function关键字可省了，fun_name随便定的函数名称。function fun_name()&#123; echo $0 #$0：文件名称 echo $1 #$1：传递的第一个参数 echo $2 #$2：传递的第二个参数&#125;fun_name 1 &quot;Yes&quot; 执行输出结果： script1234qincji:giteeblog mac$ ./test.sh ./test.sh1Yes Shell其他关键词 eval 语法：eval cmdLine，eval会对后面的cmdLine进行两遍扫描，如果在第一遍扫面后cmdLine是一个普通命令，则执行此命令；如果cmdLine中含有变量的间接引用，则保证简介引用的语义。示例如下： 编辑test.sh如下： script12345678#!/bin/bash#文件传递的长度，输出最后一个数function test() &#123; echo &quot;\\$$#&quot; #这才是我们想要的结果 eval echo &quot;\\$$#&quot;&#125;test 11 22 33 44 执行输出结果： script123qincji:giteeblog mac$ ./test.sh $444 shift 语法：shift number，位置参数可以用shift命令左移。比如shift 3表示原来的$4现在变成$1，原来的$5现在变成$2等等，原来的$1、$2、$3丢弃，$0不移动。不带参数的shift命令相当于shift 1。示例如下： 编辑test.sh如下： script123456789#!/bin/bash#文件传递的长度，输出最后一个数function test() &#123; until [ $# -eq 0 ]; do echo &quot;第一个参数为: $1 参数个数为: $#&quot; shift 2 done&#125;test 11 22 33 44 55 66 执行输出结果： script1234qincji:giteeblog mac$ ./test.sh 第一个参数为: 11 参数个数为: 6第一个参数为: 33 参数个数为: 4第一个参数为: 55 参数个数为: 2 参考 https://www.cnblogs.com/jingmoxukong/p/7867397.html","categories":[],"tags":[{"name":"ffmpeg","slug":"ffmpeg","permalink":"http://qincji.gitee.io/tags/ffmpeg/"}]},{"title":"ffmpeg configure配置选项 (转载)","slug":"ffmpeg/01_configure_help","date":"2020-12-12T14:59:35.000Z","updated":"2020-12-13T14:10:35.635Z","comments":true,"path":"2020/12/12/ffmpeg/01_configure_help/","link":"","permalink":"http://qincji.gitee.io/2020/12/12/ffmpeg/01_configure_help/","excerpt":"","text":"转自：https://blog.csdn.net/momo0853/article/details/78043903 帮助选项Help options 标准选项Standard options 许可证选项Licensing options 配置选项Configuration options 程序选项Program options 文档选项Documentation options 组件选项Component options 个别组件选项Individual component options 扩展库支持External library support 硬件加速功能hardware acceleration features 工具链选项Toolchain options 高级选项Advanced options 优化选项Optimization options 开发者选项Developer options 帮助选项（Help options） 用于查看ffmpeg的能力 选项 说明 –help print this message –list-decoders 显示所有可用的解码器（h264/mjpeg等） –list-encoders 显示所有可用的编码器（h264/mjpeg等） –list-hwaccels 显示所有支持的硬编解码器（h264_videotoolbox/h264_mediacodec等） –list-demuxers 显示所有支持解复用的容器（mp4/h264等） –list-muxers 显示所有支持复用的容器（mp4/h264等） –list-parsers show all available parsers –list-protocols 显示所有支持的传输协议（rtmp/rtp等） –list-bsfs 显示所有可用的格式转换（h264_mp4toannexb/aac_adtstoasc等） –list-indevs 显示所有支持的输入设备（alsa/v4l2等） –list-outdevs 显示所有支持的输出设备（alsa/opengl等） –list-filters 显示支持的所有过滤器（scale/volume/fps/allyuv等） 标准选项（Standard options） 编译配置 选项 说明 –logfile=FILE 配置过程中的log输出文件，默认输出到当前位置的ffbuild/config.log文件 –disable-logging 配置过程中不输出日志 –fatal-warnings 把配置过程中的任何警告当做致命的错误处理 –prefix=PREFIX 设定安装的跟目录，如果不指定默认是/usr –bindir=DIR 设置可执行程序的安装位置，默认是[PREFIX/bin] –datadir=DIR 设置测试程序以及数据的安装位置，默认是[PREFIX/share/ffmpeg] –docdir=DIR 设置文档的安装目录，默认是[PREFIX/share/doc/ffmpeg] –libdir=DIR 设置静态库的安装位置，默认是[PREFIX/lib] –shlibdir=DIR 设置动态库的安装位置，默认是[LIBDIR] –incdir=DIR 设置头文件的安装位置，默认是[PREFIX/include]；一般来说用于依赖此头文件来开发就够了 –mandir=DIR 设置man文件的安装目录，默认是[PREFIX/share/man] –pkgconfigdir=DIR 设置pkgconfig的安装目录，默认是[LIBDIR/pkgconfig]，只有--enable-shared使能的时候这个选项才有效 –enable-rpath use rpath to allow installing libraries in paths not part of the dynamic linker search path use rpath when linking programs [USE WITH CARE] –install-name-dir=DIR Darwin directory name for installed targets 许可证选项（Licensing options） 选择许可证，FFMPEG默认许可证LGPL 2.1，如果需要加gpl的库需要使用gpl的许可证，例如libx264就是gpl的，如果需要加入libx264则需要--enable-gpl。 选项 说明 –enable-gpl allow use of GPL code, the resulting libs and binaries will be under GPL [no] –enable-version3 upgrade (L)GPL to version 3 [no] –enable-nonfree allow use of nonfree code, the resulting libs and binaries will be unredistributable [no] 配置选项（Configuration options） 编译选项的配置 选项 说明 –disable-static 不生产静态库，默认生成静态库 –enable-shared 生成动态库，默认不生成动态库 –enable-small optimize for size instead of speed，默认开启 –disable-runtime-cpudetect disable detecting cpu capabilities at runtime (smaller binary)，默认开启 –enable-gray enable full grayscale support (slower color) –disable-swscale-alpha disable alpha channel support in swscale –disable-all 禁止编译所有库和可执行程序 –enable-raise-major 增加主版本号 程序选项（Program options） 可执行程序开启选项，默认编译ffmpeg中的所有可执行程序，包括ffmpeg、ffplay、ffprobe、ffserver，不过Mac平台默认情况下不生成ffplay，目前暂未知道啥原因。 选项 说明 –disable-programs do not build command line programs –disable-ffmpeg disable ffmpeg build –disable-ffplay disable ffplay build –disable-ffprobe disable ffprobe build –disable-ffserver disable ffserver build 文档选项（Documentation options） 离线文档选择 选项 说明 –disable-doc do not build documentation –disable-htmlpages do not build HTML documentation pages –disable-manpages do not build man documentation pages –disable-podpages do not build POD documentation pages –disable-txtpages do not build text documentation pages 组件选项（Component options） 除了avresample模块，默认编译所有模块。一般来说用于轻量化ffmpeg库的大小，可以仅仅开启指定某些组件的某些功能。 选项 说明 –disable-avdevice disable libavdevice build –disable-avcodec disable libavcodec build –disable-avformat disable libavformat build –disable-swresample disable libswresample build –disable-swscale disable libswscale build –disable-postproc disable libpostproc build –disable-avfilter disable libavfilter build –enable-avresample enable libavresample build [no] –disable-pthreads disable pthreads [autodetect] –disable-w32threads disable Win32 threads [autodetect] –disable-os2threads disable OS/2 threads [autodetect] –disable-network disable network support [no] –disable-dct disable DCT code –disable-dwt disable DWT code –disable-error-resilience disable error resilience code –disable-lsp disable LSP code –disable-lzo disable LZO decoder code –disable-mdct disable MDCT code –disable-rdft disable RDFT code –disable-fft disable FFT code –disable-faan disable floating point AAN (I)DCT code –disable-pixelutils disable pixel utils in libavutil 个别组件选项（Individual component options） 可以用于设定开启指定功能，例如禁止所有encoders，在这里可以开启特定的encoders（x264、aac等） 选项 说明 –disable-everything disable all components listed below –disable-encoder=NAME disable encoder NAME –enable-encoder=NAME enable encoder NAME –disable-encoders disable all encoders –disable-decoder=NAME disable decoder NAME –enable-decoder=NAME enable decoder NAME –disable-decoders disable all decoders –disable-hwaccel=NAME disable hwaccel NAME –enable-hwaccel=NAME enable hwaccel NAME –disable-hwaccels disable all hwaccels –disable-muxer=NAME disable muxer NAME –enable-muxer=NAME enable muxer NAME –disable-muxers disable all muxers –disable-demuxer=NAME disable demuxer NAME –enable-demuxer=NAME enable demuxer NAME –disable-demuxers disable all demuxers –enable-parser=NAME enable parser NAME –disable-parser=NAME disable parser NAME –disable-parsers disable all parsers –enable-bsf=NAME enable bitstream filter NAME –disable-bsf=NAME disable bitstream filter NAME –disable-bsfs disable all bitstream filters –enable-protocol=NAME enable protocol NAME –disable-protocol=NAME disable protocol NAME –disable-protocols disable all protocols –enable-indev=NAME enable input device NAME –disable-indev=NAME disable input device NAME –disable-indevs disable input devices –enable-outdev=NAME enable output device NAME –disable-outdev=NAME disable output device NAME –disable-outdevs disable output devices –disable-devices disable all devices –enable-filter=NAME enable filter NAME –disable-filter=NAME disable filter NAME –disable-filters disable all filters 扩展库支持（External library support） ffmpeg提供的一些功能是由其他扩展库支持的，如果需要使用需要明确声明，确定编译的第三方库的目标架构--arch相同就好了，在编译ffmpeg的时候需加入第三方库的头文和库搜索路径（通过extra-cflags和extra-ldflags指定即可），剩下的事ffmpeg都给你做好了。 libx264例子 ffmpeg集成libx264官方文档 $ git clone http://source.ffmpeg.org/git/ffmpeg.git $ cd x264 $ ./configure --prefix=$FFMPEG_PREFIX --enable-static --enable-shared $ make -j8 &amp;&amp; make install 选项 说明 –enable-avisynth enable reading of AviSynth script files [no] –disable-bzlib disable bzlib [autodetect] –enable-chromaprint enable audio fingerprinting with chromaprint [no] –enable-frei0r enable frei0r video filtering [no] –enable-gcrypt enable gcrypt, needed for rtmp(t)e support if openssl, librtmp or gmp is not used [no] –enable-gmp enable gmp, needed for rtmp(t)e support if openssl or librtmp is not used [no] –enable-gnutls enable gnutls, needed for https support if openssl is not used [no] –disable-iconv disable iconv [autodetect] –enable-jni enable JNI support [no] –enable-ladspa enable LADSPA audio filtering [no] –enable-libass enable libass subtitles rendering, needed for subtitles and ass filter [no] –enable-libbluray enable BluRay reading using libbluray [no] –enable-libbs2b enable bs2b DSP library [no] –enable-libcaca enable textual display using libcaca [no] –enable-libcelt enable CELT decoding via libcelt [no] –enable-libcdio enable audio CD grabbing with libcdio [no] –enable-libdc1394 enable IIDC-1394 grabbing using libdc1394 and libraw1394 [no] –enable-libebur128 enable libebur128 for EBU R128 measurement, needed for loudnorm filter [no] –enable-libfdk-aac enable AAC de/encoding via libfdk-aac [no] –enable-libflite enable flite (voice synthesis) support via libflite [no] –enable-libfontconfig enable libfontconfig, useful for drawtext filter [no] –enable-libfreetype enable libfreetype, needed for drawtext filter [no] –enable-libfribidi enable libfribidi, improves drawtext filter [no] –enable-libgme enable Game Music Emu via libgme [no] –enable-libgsm enable GSM de/encoding via libgsm [no] –enable-libiec61883 enable iec61883 via libiec61883 [no] –enable-libilbc enable iLBC de/encoding via libilbc [no] –enable-libkvazaar enable HEVC encoding via libkvazaar [no] –enable-libmodplug enable ModPlug via libmodplug [no] –enable-libmp3lame enable MP3 encoding via libmp3lame [no] –enable-libnut enable NUT (de)muxing via libnut, native (de)muxer exists [no] –enable-libopencore-amrnb enable AMR-NB de/encoding via libopencore-amrnb [no] –enable-libopencore-amrwb enable AMR-WB decoding via libopencore-amrwb [no] –enable-libopencv enable video filtering via libopencv [no] –enable-libopenh264 enable H.264 encoding via OpenH264 [no] –enable-libopenjpeg enable JPEG 2000 de/encoding via OpenJPEG [no] –enable-libopenmpt enable decoding tracked files via libopenmpt [no] –enable-libopus enable Opus de/encoding via libopus [no] –enable-libpulse enable Pulseaudio input via libpulse [no] –enable-librubberband enable rubberband needed for rubberband filter [no] –enable-librtmp enable RTMP[E] support via librtmp [no] –enable-libschroedinger enable Dirac de/encoding via libschroedinger [no] –enable-libshine enable fixed-point MP3 encoding via libshine [no] –enable-libsmbclient enable Samba protocol via libsmbclient [no] –enable-libsnappy enable Snappy compression, needed for hap encoding [no] –enable-libsoxr enable Include libsoxr resampling [no] –enable-libspeex enable Speex de/encoding via libspeex [no] –enable-libssh enable SFTP protocol via libssh [no] –enable-libtesseract enable Tesseract, needed for ocr filter [no] –enable-libtheora enable Theora encoding via libtheora [no] –enable-libtwolame enable MP2 encoding via libtwolame [no] –enable-libv4l2 enable libv4l2/v4l-utils [no] –enable-libvidstab enable video stabilization using vid.stab [no] –enable-libvo-amrwbenc enable AMR-WB encoding via libvo-amrwbenc [no] –enable-libvorbis enable Vorbis en/decoding via libvorbis, native implementation exists [no] –enable-libvpx enable VP8 and VP9 de/encoding via libvpx [no] –enable-libwavpack enable wavpack encoding via libwavpack [no] –enable-libwebp enable WebP encoding via libwebp [no] –enable-libx264 enable H.264 encoding via x264 [no] –enable-libx265 enable HEVC encoding via x265 [no] –enable-libxavs enable AVS encoding via xavs [no] –enable-libxcb enable X11 grabbing using XCB [autodetect] –enable-libxcb-shm enable X11 grabbing shm communication [autodetect] –enable-libxcb-xfixes enable X11 grabbing mouse rendering [autodetect] –enable-libxcb-shape enable X11 grabbing shape rendering [autodetect] –enable-libxvid enable Xvid encoding via xvidcore, native MPEG-4/Xvid encoder exists [no] –enable-libzimg enable z.lib, needed for zscale filter [no] –enable-libzmq enable message passing via libzmq [no] –enable-libzvbi enable teletext support via libzvbi [no] –disable-lzma disable lzma [autodetect] –enable-decklink enable Blackmagic DeckLink I/O support [no] –enable-mediacodec enable Android MediaCodec support [no] –enable-netcdf enable NetCDF, needed for sofalizer filter [no] –enable-openal enable OpenAL 1.1 capture support [no] –enable-opencl enable OpenCL code –enable-opengl enable OpenGL rendering [no] –enable-openssl enable openssl, needed for https support if gnutls is not used [no] –disable-schannel disable SChannel SSP, needed for TLS support on Windows if openssl and gnutls are not used [autodetect] –disable-sdl2 disable sdl2 [autodetect] –disable-securetransport disable Secure Transport, needed for TLS support on OSX if openssl and gnutls are not used [autodetect] –enable-x11grab enable X11 grabbing (legacy) [no] –disable-xlib disable xlib [autodetect] –disable-zlib disable zlib [autodetect] 硬件加速功能（hardware acceleration features） ffmpeg默认实现了移动端（Android和IOS）的硬编解码，可以选择disable的都是默认开启的，可以关闭，可以选择enable的都是需要自己解决依赖的。 选项 说明 –disable-audiotoolbox disable Apple AudioToolbox code [autodetect] –enable-cuda enable dynamically linked Nvidia CUDA code [no] –enable-cuvid enable Nvidia CUVID support [autodetect] –disable-d3d11va disable Microsoft Direct3D 11 video acceleration code [autodetect] –disable-dxva2 disable Microsoft DirectX 9 video acceleration code [autodetect] –enable-libmfx enable Intel MediaSDK (AKA Quick Sync Video) code via libmfx [no] –enable-libnpp enable Nvidia Performance Primitives-based code [no] –enable-mmal enable Broadcom Multi-Media Abstraction Layer (Raspberry Pi) via MMAL [no] –disable-nvenc disable Nvidia video encoding code [autodetect] –enable-omx enable OpenMAX IL code [no] –enable-omx-rpi enable OpenMAX IL code for Raspberry Pi [no] –disable-vaapi disable Video Acceleration API (mainly Unix/Intel) code [autodetect] –disable-vda disable Apple Video Decode Acceleration code [autodetect] –disable-vdpau disable Nvidia Video Decode and Presentation API for Unix code [autodetect] –disable-videotoolbox disable VideoToolbox code [autodetect] 工具链选项（Toolchain options） ffmpeg代码本身是支持跨平台的，要编译不同的平台需要配置不同平台的交叉编译工具链。ffmpeg都是c代码，所以不需要配置c++的sysroot。常用的就几个arch,cpu,cross-prefix,enable-cross-compile,sysroot,target-os,extra-cflags,extra-ldflags,enable-pic。现在Android和IOS几乎没有armv5的设备了，所以如果编译这两个平台配置armv7和armv8就好了。 选项 说明 –arch=ARCH 选择目标架构[armv7a/aarch64/x86/x86_64等] –cpu=CPU 选择目标cpu[armv7-a/armv8-a/x86/x86_64] –cross-prefix=PREFIX 设定交叉编译工具链的前缀,不算gcc/nm/as命令，例如android 32位的交叉编译链$ndk_dir/toolchains/arm-linux-androideabi-$toolchain_version/prebuilt/linux-$host_arch/bin/arm-linux-androideabi- –progs-suffix=SUFFIX program name suffix [] –enable-cross-compile 如果目标平台和编译平台不同则需要使能它 –sysroot=PATH 交叉工具链的头文件和库位，例如Android 32位位置$ndk_dir/platforms/android-14/arch-arm –sysinclude=PATH location of cross-build system headers –target-os=OS 设置目标系统 –target-exec=CMD command to run executables on target –target-path=DIR path to view of build directory on target –target-samples=DIR path to samples directory on target –tempprefix=PATH force fixed dir/prefix instead of mktemp for checks –toolchain=NAME set tool defaults according to NAME –nm=NM use nm tool NM [nm -g] –ar=AR use archive tool AR [ar] –as=AS use assembler AS [] –ln_s=LN_S use symbolic link tool LN_S [ln -s -f] –strip=STRIP use strip tool STRIP [strip] –windres=WINDRES use windows resource compiler WINDRES [windres] –yasmexe=EXE use yasm-compatible assembler EXE [yasm] –cc=CC use C compiler CC [gcc] –cxx=CXX use C compiler CXX [g++] –objcc=OCC use ObjC compiler OCC [gcc] –dep-cc=DEPCC use dependency generator DEPCC [gcc] –ld=LD use linker LD [] –pkg-config=PKGCONFIG use pkg-config tool PKGCONFIG [pkg-config] –pkg-config-flags=FLAGS pass additional flags to pkgconf [] –ranlib=RANLIB use ranlib RANLIB [ranlib] –doxygen=DOXYGEN use DOXYGEN to generate API doc [doxygen] –host-cc=HOSTCC use host C compiler HOSTCC –host-cflags=HCFLAGS use HCFLAGS when compiling for host –host-cppflags=HCPPFLAGS use HCPPFLAGS when compiling for host –host-ld=HOSTLD use host linker HOSTLD –host-ldflags=HLDFLAGS use HLDFLAGS when linking for host –host-libs=HLIBS use libs HLIBS when linking for host –host-os=OS compiler host OS [] –extra-cflags=ECFLAGS 设置cflags，如果是Android平台可以根据ndk内的设定,arm-linux-androideabi-4.6/setup.mk，建议参考你当前的setup来配置 –extra-cxxflags=ECFLAGS add ECFLAGS to CXXFLAGS [] –extra-objcflags=FLAGS add FLAGS to OBJCFLAGS [] –extra-ldflags=ELDFLAGS 参考cflags –extra-ldexeflags=ELDFLAGS add ELDFLAGS to LDEXEFLAGS [] –extra-ldlibflags=ELDFLAGS add ELDFLAGS to LDLIBFLAGS [] –extra-libs=ELIBS add ELIBS [] –extra-version=STRING version string suffix [] –optflags=OPTFLAGS override optimization-related compiler flags –build-suffix=SUFFIX library name suffix [] –enable-pic build position-independent code –enable-thumb compile for Thumb instruction set –enable-lto use link-time optimization –env=”ENV=override” override the environment variables 高级选项（Advanced options） 选项 说明 –malloc-prefix=PREFIX prefix malloc and related names with PREFIX –custom-allocator=NAME use a supported custom allocator –disable-symver disable symbol versioning –enable-hardcoded-tables use hardcoded tables instead of runtime generation –disable-safe-bitstream-reader disable buffer boundary checking in bitreaders (faster, but may crash) –enable-memalign-hack emulate memalign, interferes with memory debuggers –sws-max-filter-size=N the max filter size swscale uses [256] 优化选项（Optimization options） 默认开启各个平台的汇编优化，有些嵌入式平台可能并不能完整的支持架构的所有汇编指令，所以需要关闭。（自己理解的，没有实战） 选项 说明 –disable-asm disable all assembly optimizations –disable-altivec disable AltiVec optimizations –disable-vsx disable VSX optimizations –disable-power8 disable POWER8 optimizations –disable-amd3dnow disable 3DNow! optimizations –disable-amd3dnowext disable 3DNow! extended optimizations –disable-mmx disable MMX optimizations –disable-mmxext disable MMXEXT optimizations –disable-sse disable SSE optimizations –disable-sse2 disable SSE2 optimizations –disable-sse3 disable SSE3 optimizations –disable-ssse3 disable SSSE3 optimizations –disable-sse4 disable SSE4 optimizations –disable-sse42 disable SSE4.2 optimizations –disable-avx disable AVX optimizations –disable-xop disable XOP optimizations –disable-fma3 disable FMA3 optimizations –disable-fma4 disable FMA4 optimizations –disable-avx2 disable AVX2 optimizations –disable-aesni disable AESNI optimizations –disable-armv5te disable armv5te optimizations –disable-armv6 disable armv6 optimizations –disable-armv6t2 disable armv6t2 optimizations –disable-vfp disable VFP optimizations –disable-neon disable NEON optimizations –disable-inline-asm disable use of inline assembly –disable-yasm disable use of nasm/yasm assembly –disable-mipsdsp disable MIPS DSP ASE R1 optimizations –disable-mipsdspr2 disable MIPS DSP ASE R2 optimizations –disable-msa disable MSA optimizations –disable-mipsfpu disable floating point MIPS optimizations –disable-mmi disable Loongson SIMD optimizations –disable-fast-unaligned consider unaligned accesses slow 开发者选项（Developer options） 调试用的一些开关 选项 说明 –disable-debug disable debugging symbols –enable-debug=LEVEL set the debug level [] –disable-optimizations disable compiler optimizations –enable-extra-warnings enable more compiler warnings –disable-stripping disable stripping of executables and shared libraries –assert-level=level 0(default), 1 or 2, amount of assertion testing, 2 causes a slowdown at runtime. –enable-memory-poisoning fill heap uninitialized allocated space with arbitrary data –valgrind=VALGRIND run “make fate” tests through valgrind to detect memory leaks and errors, using the specified valgrind binary. Cannot be combined with –target-exec –enable-ftrapv Trap arithmetic overflows –samples=PATH location of test samples for FATE, if not set use $FATE_SAMPLES at make invocation time. –enable-neon-clobber-test check NEON registers for clobbering (should be used only for debugging purposes) –enable-xmm-clobber-test check XMM registers for clobbering (Win64-only; should be used only for debugging purposes) –enable-random randomly enable/disable components –disable-random –enable-random=LIST randomly enable/disable specific components or –disable-random=LIST component groups. LIST is a comma-separated list of NAME[:PROB] entries where NAME is a component (group) and PROB the probability associated with –random-seed=VALUE seed value for –enable/disable-random –disable-valgrind-backtrace do not print a backtrace under Valgrind (only applies to –disable-optimizations builds)","categories":[],"tags":[{"name":"ffmpeg","slug":"ffmpeg","permalink":"http://qincji.gitee.io/tags/ffmpeg/"}]},{"title":"本站开源代码","slug":"other/001blog/myblog","date":"2020-12-09T00:29:36.000Z","updated":"2020-12-13T14:10:35.614Z","comments":true,"path":"2020/12/09/other/001blog/myblog/","link":"","permalink":"http://qincji.gitee.io/2020/12/09/other/001blog/myblog/","excerpt":"","text":"Gitee page + Hexo {theme：pure 和 图片处理插件：hexo-image-link} + Typory 创建自己仓库，如： （1）github： 自己的项目 https://github.com/xhunmon/ 新建仓库：https://github.com/xhunmon/xhunmon.github.io 生成的自己博客地址：https://xhunmon.github.io （2）gitee： 自己的项目：https://gitee.com/qincji/ 新建仓库：https://gitee.com/qincji/qincji/ 生成的自己博客地址：https://qincji.gitee.io 克隆本项目 git clone https://github.com/xhunmon/pageblog.git 使用IDE打开项目（如：clion），进行更改 （1）更换根目录的 _config.yml 相关： url: http://qincji.gitee.io 改成上面【生成的自己博客地址】 repo: https://gitee.com/qincji/qincji.git 改成自己创建好能克隆的仓库地址 （2）更换 themes/pure/_config.yml 相关： 所有关于用户信息替换成自己的。 （3）更换 themes/pure/languages/zh-CN.yml 相关： 把中文的配置文件所有关于用户信息替换成自己的。 （4）更换 themes/pure/source 相关： 把图片资源换成自己的。 主题更多使用 项目中Hexo theme主题来自 pure ，更多配置以及API使用请前往官方文档 。 图片处理插件安装 使用命令 （1）删除自动生成的文件 hexo clean （2）生成网页等文件 hexo g （3）开启预览服务，浏览器中输入：http://localhost:4000/ hexo s （4）更新到github/gitee仓库 hexo d （5）如果是gitee仓库必须去当前项目的gitee page页面手动更新 nmp代理的两种方式 (1）方式一：安装cnpm镜像代理；安装后使用 cnpm命令代替cpm npm install -g cnpm --registry=https://registry.npm.taobao.org cnpm install -g @angular/cli （2）方式二： npm config set registry https://registry.npm.taobao.org 其他 搭建过程请前往：我的博客搭建笔记","categories":[],"tags":[{"name":"其他","slug":"其他","permalink":"http://qincji.gitee.io/tags/%E5%85%B6%E4%BB%96/"}]},{"title":"直播推流全过程：总纲","slug":"rtmppush/outline","date":"2020-12-08T05:30:20.000Z","updated":"2020-12-13T14:10:35.599Z","comments":true,"path":"2020/12/08/rtmppush/outline/","link":"","permalink":"http://qincji.gitee.io/2020/12/08/rtmppush/outline/","excerpt":"","text":"本系列介绍了rtmp直播推流全过程 完整的项目地址 以下文章是针对每一个情况，介绍音视频相关知识，以及实现的原理，总共分五章： 第一章：直播推流全过程：视频数据源之YUV（1） RGB或YUV 组成一张画面，很多个的画面就可以组成一个视频，而在视频编解码领域中YUV则是这一切的基础。 第二章：直播推流全过程：音频数据源之PCM（2） 音频处理就是对声音特性采集成数字信号后进行处理，而PCM则是最原始采集到的数据，称“裸流”。 第三章：直播推流全过程：视频编码之H.264（3） 为了减少视频大小，以及改善网络传输，H.264编码在网络传输中可是非常重要。 第四章：直播推流全过程：音频编码之AAC（4） acc编码是音频公认的主流编码。 第五章：直播推流全过程：直播推流编码之RTMP（5） 结合rtmp分块的特性，把数据较大的视频数据进行分块传输，这必定是直播界的宠儿！","categories":[],"tags":[{"name":"直播推流全过程","slug":"直播推流全过程","permalink":"http://qincji.gitee.io/tags/%E7%9B%B4%E6%92%AD%E6%8E%A8%E6%B5%81%E5%85%A8%E8%BF%87%E7%A8%8B/"}]},{"title":"直播推流全过程：直播推流编码之RTMP（5）","slug":"rtmppush/5-rtmp","date":"2020-12-08T05:10:30.000Z","updated":"2020-12-13T14:10:35.585Z","comments":true,"path":"2020/12/08/rtmppush/5-rtmp/","link":"","permalink":"http://qincji.gitee.io/2020/12/08/rtmppush/5-rtmp/","excerpt":"","text":"简述 Adobe 公司的实时消息传输协议 (RTMP) 通过一个可靠地流传输提供了一个双向多通道消息服务，意图在通信端之间传递带有时间信息的视频、音频和数据消息流。 Handshake Diagram（握手流程） Uninitialized (未初始化)： 客户端发送C0包(1 字节，版本信息)，如果服务器支持这个版本会响应S0和S1，否则终止连接。 Version Sent (版本已发送)： 当服务器接收到版本号后(已发送S0和S1)，客户端等S1，服务器等C1，当都接收后，客户端发送C2，服务器发送S2，然后两者状态变成Ack Sent。 Ack Sent (确认已发送)： 客户端和服务器分别等待 S2 和 C2。 Handshake Done (握手结束)： 客户端和服务器可以开始交换消息了。 分块 网络传输过程中，每一个块（每个rtmp包）必须被完全发送才可以发送下一块，而在接收端，这些块被根据 chunk stream ID 被组装成消息。分块允许上层协议将大的消息分解为更小的消息，例如，防止体积大的但优先级小的消息 (比如视频) 阻碍体积较小但优先级高的消息 (比如音频或者控制命令)。分块也让我们能够使用较小开销发送小消息，因为块头包含包含在消息内部的信息压缩提示。下面块格式就是一个块的组成。（注意：当连续接收到chunk stream ID 相同时，这些快是同一个消息，需要合并。） Chunk Format（块格式） 下图大致的概括了一块的组成，从当前块的 第一个字节 大致能分析出该块头的组成信息。 Extended Timestamp 和 Chunk Data具体计算在下面介绍。 Basic Header（块基本头） cs id保留0和1的值，而2的值保留用于下层协议控制消息和命令；具体如下： 第一个字节低6bit值&gt;1： Basic Header 为1byte；fmt=2bit；cs id =6bit，范围：2-63（也就是6bit最大能支持的范围）。 fmt cs id 高2bit 低6bit 如：0100 1010-&gt;fmt：01… …=2；cs id：…00 1010=10 第一个字节低6bit值=0： Basic Header 为2byte；fmt=2bit；此时第一个字节中后6bit的值为0，cs id=第2个byte，范围：64 ~ 319（也就是第2个byte的值 + 64）。 fmt 0 cs id - 64 高2bit 低6bit byte 如：1000 0000 0001 0001-&gt;fmt：10… …=2；0：…00 0000；cs id：(0001 0001)+64=17+64=81 第一个字节低6bit值=1： Basic Header 为3byte；fmt=2bit；此时第一个字节中后6bit的值为0，cs id=第2个byte，范围：64~65599（(第3个byte) * 256 + (第2个byte) + 64）。 fmt 1 cs id - 64 高2bit 低6bit 2byte 如：1100 0000 0001 0001 0010 0010-&gt;fmt：11… …=2；1：…00 0001；cs id：(0010 0010)x256 + (0001 0001)+64=8704 + 17 + 64=8785 Message Header（块消息头） 根据块基本头中的 fmt 的值来区分块消息头，从0—3共4种，上图标的很明确了，具体如下： fmt = 0： 块消息头为11字节，当前消息的 timestamp 在这表示(此时 Extended Timestamp 辅助用)，如果用户设置时间戳&gt;=0xFFFFFF时(3字节容不下了)时，timestamp 字段就固定为0xFFFFFF。message length 是指 Chunk Data 的大小。Extended Timestamp 字段用4字节表示； timestamp message length message type id message stream id 3byte 3byte 1byte 4byte fmt = 1： 块消息头为7字节，少了 message stream id ，这一块使用前一块一样的流 ID。 timestamp delta message length message type id 3byte 3byte 1byte fmt = 2： 块消息头为3字节，只有 timestamp delta ，计算方式同 fmt = 0 时一样处理；流 ID与 fmt = 1 相同。 fmt = 3： 无块消息头；流 ID与 fmt = 1 相同；当一个消息被切割成多块时，除第一块外，其他都应 fmt = 3。 Extended Timestamp（扩展时间戳） 当块消息头中的 timestamp 或者 timestamp delta 字段(3字节)容不下时(fmt = 0，1或2)，Extended Timestamp 才会被使用。 RTMPDump tmpdump 是一个用来处理 RTMP 流媒体的工具包，支持 rtmp://, rtmpt://, rtmpe://, rtmpte://, and rtmps:// 等。源码详细api以及流程图请看雷神的RTMPdump 源代码分析 1： main()函数 ，这里只是简单介绍，集成到android中使用。因为源码很少，所以直接在as中进行编译生成静态库。 （1）下载：http://rtmpdump.mplayerhq.hu/download/rtmpdump-2.3.tgz （2）把源码导入到as中，如下图所示： librtmp/CMakeLists.txt文件配置： 1234567cmake_minimum_required(VERSION 3.4.1)#预编译宏set(CMAKE_C_FLAGS &quot;$&#123;CMAKE_C_FLAGS&#125; -DNO_CRYPTO&quot; )#所有源文件放入 rtmp_source 变量file(GLOB rtmp_source *.c)#编译静态库add_library(rtmp STATIC $&#123;rtmp_source&#125; ) 项目的CMakeLists.txt文件引用编译生成的静态库 12345678...# 引入指定目录下的CMakeLists.txtadd_subdirectory($&#123;CMAKE_SOURCE_DIR&#125;/librtmp)...#4、链接到库文件，jni/c/c++可以引入链接到target_link_libraries( rtmp ...) 参考 （1）rtmp_specification_1.0 （2）https://www.cnblogs.com/Kingfans/p/7083100.html （3）https://blog.csdn.net/commshare/article/details/103393461 （4）https://blog.csdn.net/leixiaohua1020/article/details/12952977","categories":[],"tags":[{"name":"直播推流全过程","slug":"直播推流全过程","permalink":"http://qincji.gitee.io/tags/%E7%9B%B4%E6%92%AD%E6%8E%A8%E6%B5%81%E5%85%A8%E8%BF%87%E7%A8%8B/"}]},{"title":"直播推流全过程：音频编码之AAC（4）","slug":"rtmppush/4-aac","date":"2020-12-07T14:30:15.000Z","updated":"2020-12-13T14:10:35.605Z","comments":true,"path":"2020/12/07/rtmppush/4-aac/","link":"","permalink":"http://qincji.gitee.io/2020/12/07/rtmppush/4-aac/","excerpt":"","text":"回顾 还记得我们采集到的PCM原始数据流（俗称裸流）吗？由于PCM裸流过大，不便于储存与传输，于是就出现了针对于PCM裸流的压缩编码标准，包含AAC，MP3，AC-3 等等（wiki audio file format）；而AAC则是当前的主流。这里的AAC指的是一套编码标准（协议），而faac是一个开源的AAC编解码工具。 简述 AAC：高级音频编码(Advanced Audio Coding)，基于MPEG-2的音频编码技术，目的是取代MP3格式。2000年，MPEG-4标准出现后，AAC重新集成了其特性，为了区别于传统的MPEG-2 AAC又称为MPEG-4 AAC。 AAC的音频文件格式 AAC的音频文件格式有两种ADIF和ADTS。这两种格式主要区别：ADIF只有一个文件头，ADTS每个包前面有一个文件头。而我们重点讲解的是ADTS格式。 ADIF Audio Data Interchange Format 音频数据交换格式。这种格式的特征是可以确定的找到这个音频数据的开始，不需进行在音频数据流中间开始的解码，即它的解码必须在明确定义的开始处进行。故这种格式常用在磁盘文件中。编码格式如下： 在MPEG-2 AAC中ADIF语法规则如下： ADTS Audio Data Transport Stream 音频数据传输流。这种格式的特征是它是一个有同步字的比特流，解码可以在这个流中任何位置开始。也就是说ADTS的每一帧都有一个header和aac音频数据，这可以在网络传输的时候进行实时解码。 下图为ADTS的组成部分以及在MPEG-2 AAC的语法结构： 下图为ADTS的组成部分以及在MPEG-4 AAC的语法结构： 注：ES：全称elementary stream，这里意为编码后的音频数据。 adts_fixed_header关键参数如下： syncword 恒为 ‘1111 1111 1111’，也就是0xFFF。作为每个adts_freme的分割。 ID 使用那个MPEG版本。0：MPEG-4，1：MPEG-2。 layer 应该恒 为‘00’。 protection_absent 是否使用error_check()。0：使用，1：不使用。 profile(MPEG-4:profile_ObjectType) 见下表（左边是MPEG-2版本；右边是MPEG-4版本，Profile_ObjectType的值）： sampling_frequency_index 采样率的数组下标，即：sampling frequeny[sampling_frequency_index] ： private_bit 私有位，编码时设置为0，解码时忽略。 channel_configuration 声道数。 original_copy 编码时设置为0，解码时忽略。 home 编码时设置为0，解码时忽略。 adts_variable_header关键参数如下： copyright_identification_bit 72位版权标识字段中的一位。 copyright_identification_start 一位表示 该音频帧中的copyright_identification_bit是 72位版权标识的第一位。如果不 版权标识已传输，此位应 保持为’0’。'0’在 此音频帧“ 1”开始在 此音频帧。 frame_length(MPEG-4:aac_frame_length) 帧的长度，包括header和以字节为单位的error_check。 adts_buffer_fullness 固定0x7FF，表示比特流是可变速率比特流。 number_of_raw_data_blocks_in_frame 在ADTS帧中有number_of_raw_data_blocks_in_frame + 1个AAC原始数据块。number_of_raw_data_blocks_in_frame == 0 表示说ADTS帧中有一个AAC原始数据块。 下图为一个ADTS格式的文件开头部分 我们来数一个第一个frame的header 1234567891011121314151617181920212223####adts_fixed_header()#-------FFF1---------1111 1111 1111 .... #0xFFF; syncword的值.... .... .... 0... #ID=0;使用MPEG-4.... .... .... .00. #layer.... .... .... ...0 #protection_absent，不使用error_check()#-------4C80---------01.. .... .... .... #Profile_ObjectType=AAC MAIN..00 11.. .... .... #sampling_frequency_index=3,采样率为48000.... ..0. .... .... #private_bit.... ...0 10.. .... #channel_configuration=2（声道数）.... .... ..0. .... #original_copy.... .... ...0 .... #home####adts_variable_header()#-------(4C8)0---------.... .... .... 0... #copyright_identification_bit.... .... .... .0.. #copyright_identification_start#-------(4C8)0 223F--------..00 0010 0010 001. .... #aac_frame_length=0x111=273字节--&gt;下一帧到上图的FFF14C#-------(22)3F FC--------...1 1111 1111 11.. #adts_buffer_fullness=0x7FF#-------(F)C--------..00 #number_of_raw_data_blocks_in_frame faac开源库 （1）下载 https://nchc.dl.sourceforge.net/project/faac/faac-src/faac-1.29/faac-1.29.9.2.tar.gz （2）编译生成静态库（这里是android的交叉编译脚本，ndk21，平台mac） 12345678910111213141516171819202122232425#!/bin/bashPREFIX=`pwd`/android/armeabi-v7aNDK_ROOT=/Users/Qincji/Desktop/develop/android/source/sdk/ndk/android-ndk-r21# 注意：Mac为darwin-x86_64，linux为linux-x86_64；一定要确保路径真实有效TOOLCHAIN=$NDK_ROOT/toolchains/llvm/prebuilt/darwin-x86_64CROSS_COMPILE=$TOOLCHAIN/bin/arm-linux-androideabi#在android studio中新建一个NDK项目，并且保持NDK版本与这里的一致。该FLAGS从build.ninja文件中拷贝。FLAGS=&quot;-g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -march=armv7-a -mthumb -Wformat -Werror=format-security -Oz -DNDEBUG -fPIC&quot;export CC=$TOOLCHAIN/bin/armv7a-linux-androideabi21-clangexport CXX=$TOOLCHAIN/bin/armv7a-linux-androideabi21-clang++export CFLAGS=&quot;$FLAGS&quot;export PATH=$PATH:$TOOLCHAIN/bin ./configure \\--prefix=$PREFIX \\--host=arm-linux-androideabi \\--with-pic \\--enable-shared=no make cleanmake install （3）移入项目中 并且配置CMakeList.txt文件 1234567...include_directories(include)...target_link_libraries( ... faac ) （4）API简单使用 1234567891011121314151617181920212223//1.打开编码器，获取inputSamples和maxOutputBytes的值，用于后面编码//1：采样率；2：声道数；3：单次输入的样本数；4：输出数据最大字节数faacEncOpen(unsigned long sampleRate,unsigned int numChannels,unsigned long *inputSamples,unsigned long *maxOutputBytes);//2.设置编码器参数faacEncConfigurationPtr config = faacEncGetCurrentConfiguration(faacEncHandle hEncoder);//指定mpeg4编码标准config-&gt;mpegVersion = MPEG4;//config-&gt;mpegVersion = MPEG2;//lc 标准config-&gt;aacObjectType = LOW;//16位config-&gt;inputFormat = FAAC_INPUT_16BIT;// 编码出原始数据；0 = Raw; 1 = ADTSconfig-&gt;outputFormat = 1;faacEncSetConfiguration(faacEncHandle hEncoder, config);//3.进行编码//1：FAAC的handle；2：采集的pcm的原始数据；3：从faacEncOpen获取的inputSamples；4：至少有从faacEncOpen获取maxOutputBytes大小的缓冲区；5：从faacEncOpen获取maxOutputBytes//返回值为编码后数据字节的长度int encodeLenght = faacEncEncode(faacEncHandle hEncoder, int32_t * inputBuffer, unsigned int samplesInput, unsigned char *outputBuffer, unsigned int bufferSize); 参考 AAC格式简介 wiki audio file format https://csclub.uwaterloo.ca/~ehashman/ISO14496-3-2009.pdf [AAC ADTS格式分析](","categories":[],"tags":[{"name":"直播推流全过程","slug":"直播推流全过程","permalink":"http://qincji.gitee.io/tags/%E7%9B%B4%E6%92%AD%E6%8E%A8%E6%B5%81%E5%85%A8%E8%BF%87%E7%A8%8B/"}]},{"title":"直播推流全过程：视频编码之H.264（3）","slug":"rtmppush/3-h264","date":"2020-12-06T08:54:50.000Z","updated":"2020-12-11T01:05:56.544Z","comments":true,"path":"2020/12/06/rtmppush/3-h264/","link":"","permalink":"http://qincji.gitee.io/2020/12/06/rtmppush/3-h264/","excerpt":"","text":"简单说说编码 当我们把摄像头采集画面直接写入到文件中时，我们会发现没一会文件已经非常大了。这导致很不适合保存和传输，所以需要编码，把画面数据进行压缩。视频编码标准有很多，而我们这里讲的是H.264编码。其他请看：视频编码标准汇总及比较。 H.264编码 制订H.264的主要目标有两个： （1）视频编码层(VCL，全称：Video Coding Layer)：得到高的视频压缩比。 （2）网络提取层(NAL，全称：Network Abstraction Layer)：具有良好的网络亲和性，即可适用于各种传输网络。而NAL则是以NALU（NAL Unit）为单元来支持编码数据在基于包交换技术网络中传输的。 编码的输入与输出 一张张画面通过以H.264编码标准的编码器(如x264)编码后，输出一段包含N个NALU的数据，每个NALU之间通过起始码来分隔，如图： 起始码： 0x00 00 01 或者 0x00 00 00 01。 在网络传输（如RTMP）或者一些容器中（如FLV），通常会把NALU整合到视频区域的数据中。如下图的flv格式： 所以这篇文章主要学习NALU的基本知识，学会如何去分析一段NALU数据。 NALU（NAL 单元） NALU(NAL Unit，NAL 单元)的组成部分如下图。其中，f(0)占1bit，u(2)占2bit，u(5)占5bit，文中如有出现类似描述符请看H.264描述符。 从上图可以看出来，当前NAL单元属于什么样的类型，这取决于RBSP具体是什么样的类型，而RBSP的类型是根据nal_unit_type的值来定义的。 ①当nal_unit_type为1~5时：RBSP为切片类型（有5种切片类型）；整个NAL单元类型为VCL NAL单元，VCL是上面说的视频编码层，里面有编码后画面数据。 ②当nal_unit_type为其他时：RBSP为序列参数集类型、图像参数集类型等等；整个NAL单元类型为非VCL NAL单元。 具体的nal_unit_type所对应的RBSP类型如下表所示： nal_unit_type NAL 单元和 RBSP 语法结构的内容 0 未指定 1 一个非IDR图像的编码条带slice_layer_without_partitioning_rbsp( ) 2 编码条带数据分割块Aslice_data_partition_a_layer_rbsp( ) 3 编码条带数据分割块Bslice_data_partition_b_layer_rbsp( ) 4 编码条带数据分割块Cslice_data_partition_c_layer_rbsp( ) 5 IDR图像的编码条带slice_layer_without_partitioning_rbsp( ) 6 辅助增强信息 (SEI)sei_rbsp( ) 7 序列参数集（SPS）seq_parameter_set_rbsp( ) 8 图像参数集(PPS)pic_parameter_set_rbsp( ) 9 访问单元分隔符access_unit_delimiter_rbsp( ) 10 序列结尾end_of_seq_rbsp( ) 11 流结尾end_of_stream_rbsp( ) 12 填充数据filler_data_rbsp( ) 13 序列参数集扩展seq_parameter_set_extension_rbsp( ) 14…18 保留 19 未分割的辅助编码图像的编码条带slice_layer_without_partitioning_rbsp( ) 20…23 保留 24…31 未指定 SPS（序列参数集） SPS全称 Sequence parameter set(序列参数集)，当nal_unit_type=7时，RBSP就是SPS类型，也可以说NAL单元为SPS的NAL单元。SPS主要包含的是针对一连续编码视频序列的参数，如帧数、图像尺寸等；详见下表 序列参数集RBSP 语法： 上面中的主要参数的含义： profile_idc 档次（H.264编码标准有几个档次）：66=基本；77=主要；88=扩展… seq_parameter_set_id 标识符，本序列的id号，会被PPS引用。 num_ref_frames 指定参考帧队列可能达到的最大长度。 pic_width_in_mbs_minus1 加1是指以宏块为单元的每个解码图像的宽度。 pic_height_in_map_units_minus1 加1表示以条带组映射为单位的一个解码帧或场的高度。 下面为从一个只放h.264视频编码文件的一段（SPS）： ue(v)和se(v)的计算公式见 H.264描述符。 1234567891011121314151617181920212223242526272829303132# 00000001 6764001E ACD940A0 2FF96100 00030001 00000300 320F162D 9600000001 #起始码#NAL单元头---0x67 0110 0111 --------------0... .... # forbidden_zero_bit --&gt;u(1).11. .... # nal_ref_idc --&gt;u(2) --&gt;HIGHEST...0 0111 # nal_unit_type --&gt;u(5) --&gt;SPS64 # profile_idc=103 --&gt;u(8) #---0x00 0000 0000 --------------0... .... #constraint_set0_flag.0.. .... #constraint_set1_flag..0. .... #constraint_set2_flag...0 .... #constraint_set3_flag.... 0000 #reserved_zero_4bits1E # level_idc --&gt;u(8) --&gt; 30#-----------0xAC 1010 1100 --------------1... .... # seq_parameter_set_id --&gt; ue(v) --&gt; 0.010 .... # log2_max_frame_num_minus4 --&gt; ue(v) --&gt; 1.... 1... # pic_order_cnt_type --&gt; ue(v) --&gt;1 执行else if( pic_order_cnt_type == 1 ).... .1..#delta_pic_order_always_zero_flag --&gt;u(1)#----------0xACD9 (1010 11)00 1101 1001 ====== 括号里面的bit上面已使用.... ..00 110. .... #offset_for_non_ref_pic --&gt;se(v)-&gt;codeNum=5-&gt;value=3.... .... ...1 .... #offset_for_top_to_bottom_field --&gt;se(v)-&gt;codeNum=0-&gt;value=0.... .... .... 1... #num_ref_frames_in_pic_order_cnt_cycle --&gt;ue(v)-&gt;0#----------0xD940 (1101 1)001 0100 0000 ====== 括号里面的bit上面已使用.... .001 01.. .... #num_ref_frames --&gt;ue(v)-&gt;4.... .... ..0. .... #gaps_in_frame_num_value_allowed_flag --&gt;u(1)-&gt;0#----------0x40A0 (010)0 0000 1010 0000 ====== 括号里面的bit上面已使用...0 0000 1010 00.. #pic_width_in_mbs_minus1 --&gt;ue(v)-&gt;32-1+8=39#----------0xA02F (1010 00)00 0010 1111 ====== 括号里面的bit上面已使用.... ..00 0010 111. #pic_height_in_map_units_minus1 --&gt;ue(v)-&gt;16-1+7=22…………就到这里了，偷个懒，有兴趣大家自己分析下去，哈哈 PPS（图像参数集） PPS全称picture parameter set(图像参数集)，当nal_unit_type=8时，RBSP就是PPS类型，也可以说NAL单元为SPS的NAL单元。一个序列中某一幅图像或者某几幅图像，其参数如标识符pic_parameter_set_id、可选的seq_parameter_set_id、熵编码模式选择标识、片组数目、初始量化参数和去方块滤波系数调整标识等；详见下表 图像参数集RBSP 语法： X264 这是国际好评的H.264协议标准的编码工具，这里简单介绍一下如何使用。 （1）下载：https://www.videolan.org/developers/x264.html （2）编译（android的交叉编译，平台：Mac） 1234567891011121314151617181920212223242526272829303132333435#!/bin/sh##########脚本忘记是参考哪位大神的了###########ndk的路径NDK=/Users/Qincji/Desktop/develop/android/source/sdk/ndk/android-ndk-r17cAPI=17 #最低支持Android版本#编译平台darwin-x86_64为mac，linux-x86_64为linuxHOST_PLATFORM=darwin-x86_64function build_x264 &#123; OUTPUT=$(pwd)/&quot;android&quot;/&quot;$CPU&quot; ./configure \\ --prefix=$OUTPUT \\ --cross-prefix=$CROSS_PREFIX \\ --sysroot=$SYSROOT \\ --host=$HOST \\ --disable-asm \\ --disable-shared \\ --enable-static \\ --disable-opencl \\ --enable-pic \\ --disable-cli \\ --extra-cflags=&quot;$EXTRA_CFLAGS&quot; \\ --extra-ldflags=&quot;$EXTRA_LDFLAGS&quot; make clean make install echo &quot;编译结束，路径如下：&quot; echo &quot;$OUTPUT&quot; &#125; CPU=&quot;armeabi-v7a&quot;CROSS_PREFIX=$NDK/toolchains/arm-linux-androideabi-4.9/prebuilt/darwin-x86_64/bin/arm-linux-androideabi-SYSROOT=$NDK/platforms/android-$API/arch-arm/EXTRA_CFLAGS=&quot;-D__ANDROID_API__=$API -isysroot $NDK/sysroot -I$NDK/sysroot/usr/include/arm-linux-androideabi -Os -fPIC -marm&quot;EXTRA_LDFLAGS=&quot;-marm&quot;HOST=arm-linuxbuild_x264 （3）把编译生成的静态库移入android studio 在CMakeList.txt文件中添加： 1234567...include_directories(include)...target_link_libraries( ... x264 ) （4）API简单使用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192/**关键步骤，来自雷神：https://blog.csdn.net/leixiaohua1020/article/details/42078645x264_param_default()：设置参数集结构体x264_param_t的缺省值。x264_picture_alloc()：为图像结构体x264_picture_t分配内存。x264_encoder_open()：打开编码器。x264_encoder_encode()：编码一帧图像。x264_encoder_close()：关闭编码器。x264_picture_clean()：释放x264_picture_alloc()申请的资源。 存储数据的结构体如下所示。x264_picture_t：存储压缩编码前的像素数据。x264_nal_t：存储压缩编码后的码流数据。*/int X264Rtmp::encode(const char *url, int width, int height, int bitRate, int fps) &#123; //计算一帧等信息 int ySize = width * height; int uvSize = ySize / 4; FILE *fp_src = fopen(url, &quot;rb&quot;); //初始化VLC图片编码层的参数 x264_picture_t *pic_in = (x264_picture_t *) malloc(sizeof(x264_picture_t)); x264_t *videoCodec = 0; x264_param_t param; x264_param_default(&amp;param); //根据应用场景设置编码速度，以及编码质量。2：x264_preset_names，3：x264_tune_names x264_param_default_preset(&amp;param, x264_preset_names[0], x264_tune_names[7]); //输入数据格式， yuv 4:2:0 param.i_csp = X264_CSP_I420; param.i_width = width; param.i_height = height; //base_line 3.2 编码规格，影响网络带宽，图像分辨率等。 -- https://en.wikipedia.org/wiki/Advanced_Video_Coding param.i_level_idc = 32; //两张参考图片间b帧的数量 param.i_bframe = 0; //参数i_rc_method表示码率控制，CQP(恒定质量)，CRF(恒定码率)，ABR(平均码率) param.rc.i_rc_method = X264_RC_ABR; //比特率(码率, 单位Kbps) param.rc.i_bitrate = bitRate / 1000; //瞬时最大码率 param.rc.i_vbv_max_bitrate = bitRate / 1000 * 1.2; //设置了i_vbv_max_bitrate必须设置此参数，码率控制区大小,单位kbps param.rc.i_vbv_buffer_size = bitRate / 1000; //帧率（每秒显示多少张画面） param.i_fps_num = fps; param.i_fps_den = 1; param.i_timebase_den = param.i_fps_num; param.i_timebase_num = param.i_fps_den;// param.pf_log = x264_log_default2; //用fps而不是时间戳来计算帧间距离 param.b_vfr_input = 0; //帧距离(关键帧) 2s一个关键帧 param.i_keyint_max = fps * 2; // 是否复制sps和pps放在每个关键帧的前面 该参数设置是让每个关键帧(I帧)都附带sps/pps。 param.b_repeat_headers = 1; //多线程 param.i_threads = 1; x264_param_apply_profile(&amp;param, &quot;baseline&quot;); //打开编码器 videoCodec = x264_encoder_open(&amp;param); x264_picture_alloc(pic_in, X264_CSP_I420, width, height); //编码：h264码流 while (!feof(fp_src)) &#123; //y数据 fread(pic_in-&gt;img.plane[0], ySize, 1, fp_src); //Y fread(pic_in-&gt;img.plane[1], uvSize, 1, fp_src); //U fread(pic_in-&gt;img.plane[2], uvSize, 1, fp_src); //V //编码出来的数据 （帧数据） x264_nal_t *pp_nal; //编码出来有几个数据 （多少帧） int pi_nal; x264_picture_t pic_out; x264_encoder_encode(videoCodec, &amp;pp_nal, &amp;pi_nal, pic_in, &amp;pic_out); //如果是关键帧 3 int sps_len; int pps_len; uint8_t sps[100]; uint8_t pps[100]; // chroma_format_idc for (int i = 0; i &lt; pi_nal; ++i) &#123; x264_nal_t &amp;nal = pp_nal[i]; if (nal.i_type == NAL_SPS) &#123; &#125; else if (nal.i_type == NAL_PPS) &#123; &#125; else &#123; &#125; &#125; &#125;&#125; 参考 视频编码标准汇总及比较 H.264-AVC-ISO_IEC_14496-10 新一代视频压缩编码标准-H.264_AVC(第二版) https://stackoverflow.com/questions/28421375/usage-of-start-code-for-h264-video/29103276 https://blog.csdn.net/engineer_james/article/details/81750864 x264流程 x264参数注释","categories":[],"tags":[{"name":"直播推流全过程","slug":"直播推流全过程","permalink":"http://qincji.gitee.io/tags/%E7%9B%B4%E6%92%AD%E6%8E%A8%E6%B5%81%E5%85%A8%E8%BF%87%E7%A8%8B/"}]},{"title":"我的博客搭建笔记","slug":"other/001blog/notes","date":"2020-12-04T14:59:35.000Z","updated":"2020-12-13T14:10:35.499Z","comments":true,"path":"2020/12/04/other/001blog/notes/","link":"","permalink":"http://qincji.gitee.io/2020/12/04/other/001blog/notes/","excerpt":"","text":"选择GitHub Page的原因是比其他平台爽！ 且免费，还能拥有自己独立门户！大家用过其他平台的都不少有吐槽的地方吧？说说我搭建的过程和思路。 选择套餐（Mac平台）： Github Page + Hexo（主题：pure；插件：hexo-image-link）+ Typory （1）搭建GitHub Pages 和 Hexo ，注意点：①仓库名必须为：昵称.github.io`，访问时是：https://昵称.github.io作为首页。②主题选择下面（2）的。 （2）Hexo主题选择hexo-theme-pure，注意：①路径复制到的目录应该是下图位置；②categories文章分类并不会合并，所以我只用tags。 （3）使用Hexo插件hexo-image-link解决图片问题，以及Typory工具写markdown文章 记录hexo的几个关键命令： （1）删除自动生成的文件 hexo clean （2）生成网页等文件 hexo g （3）开启预览服务，浏览器中输入：http://localhost:4000/ hexo s （4）更新到github仓库 hexo d nmp代理 （1）方式一：安装cnpm镜像代理；安装后使用 cnpm命令代替cpm npm install -g cnpm --registry=https://registry.npm.taobao.org cnpm install -g @angular/cli （2）方式二： npm config set registry https://registry.npm.taobao.org","categories":[],"tags":[{"name":"其他","slug":"其他","permalink":"http://qincji.gitee.io/tags/%E5%85%B6%E4%BB%96/"}]},{"title":"直播推流全过程：音频数据源之PCM（2）","slug":"rtmppush/2-pcm","date":"2020-12-04T10:10:20.000Z","updated":"2020-12-13T14:10:35.593Z","comments":true,"path":"2020/12/04/rtmppush/2-pcm/","link":"","permalink":"http://qincji.gitee.io/2020/12/04/rtmppush/2-pcm/","excerpt":"","text":"声音与音频 声音是波，成为声波，而声波的三要素是频率、振幅和波形。频率代表音阶的高低（女高音、男低音）单位赫兹（Hz），人耳能听到的声波范围：频率在20Hz~20kHz之间；振幅代表响度（音量）；波形代表音色。而我们音频处理就是对声波采集成数字信号后进行处理。 音频采集与关键名词 音频采集的过程主要是通过设备设置采样率、采样数，将音频信号采集为pcm（Pulse-code modulation，脉冲编码调制）编码的原始数据（无损压缩），然后编码压缩成mp3、aac等封装格式的数据。音频关键知识： 采样率： 一段音频数据中单位时间内（每秒）采样的个数。 位宽： 一次最大能传递数据的宽度，可以理解成放单个采集数据的内存。常有8位和16位，而8位：代表着每个采集点的数据都使用8位（1字节）来存储；16位：代表着每个采集点的数据都使用16位（2字节）来存储。 声道数： 扬声器的个数，单声道、双声道等。每一个声道都占一个位宽。 来一张图来描述一下： 一段时间内的数据大小如何计算？ 采样率 x (位宽 / 8) x 声道数 x 时间 = 数据大小（单位：字节） 比如 2分钟的CD（采样率为：44100，位宽：16，声道数：2）的数据大小：44100 x (16 / 8) x 2 x 120 = 20671.875 Byte 约为 20.18M。 PCM数据的基本使用 我们采集到的pcm原始数据要怎么玩？首先得知道怎么这些数据都代表啥意思，然后才能入手处理。 1、pcm数据时如何组成（存储）？ 举个例子，分别使用不同的方式存储一段采集数据 0x11 0x22 0x33 0x44 0x55 0x66 0x77 0x88 总共8个字节。 8位单声道： 按照数据采集时间顺序存储，即：0x11 0x22 0x33 0x44 0x55 0x66 0x77 0x88 8位双声道： L声道-R声道-L声道-R声道形式存储，即：0x11(L) 0x22® 0x33(L) 0x44® …… 16位单声道： 首先从 维基多媒体：pcm了解到位宽大于8位时，字节的排序方式是有差别的，描述如下： When more than one byte is used to represent a PCM sample, the byte order (big endian vs. little endian) must be known. Due to the widespread use of little-endian Intel CPUs, little-endian PCM tends to be the most common byte orientation. 当使用一个以上的字节表示PCM样本时，必须知道字节顺序（大端与小端）。由于低端字节Intel CPU的广泛使用，低端字节PCM往往是最常见的字节方向。 举个栗子：当位宽为16位（2字节）存储一个采集数据时，如：0x12ab，大端和小端分别是： big-endian: 0x12 0xab； little-endian: 0xab 0x12。 所以： big-endian存储方式：0x1122 0x3344 0x5566 0x7788； little-endian存储方式：0x2211 0x4433 0x6655 0x8877。 16位双声道： L声道-R声道-L声道-R声道形式存储： big-endian：0x1122(L) 0x3344® 0x5566(L) 0x7788® little-endian: 0x2211(L) 0x4433® 0x66550(L) 0x8877® 2、pcm原始数据可以怎么玩？ 将little-endian_2_44100_16.pcm采样数据进行切割，只保留后面5秒的数据 123456789101112131415161718192021222324/** * 将little-endian_2_44100_16.pcm采样数据进行切割，只保留后面5秒的数据 * 1、该类型数据5秒有多长？ * 2、从哪里开始截取？ */int cut5second(const char *url)&#123; FILE *in = fopen(url, &quot;rb+&quot;); FILE *out = fopen(&quot;./output/spit5second.pcm&quot;, &quot;wb+&quot;); long long data5Length = 44100 * (16/8) * 2 * 5; struct stat statbuf; stat(url,&amp;statbuf); long long fileLength = statbuf.st_size; long long start = fileLength - data5Length; char *simple = (char *)malloc(data5Length); //把指针位置移动到start位置开始读取 fseek(in,start,1); //每次从in文件中读取1组data5Length个长度数据的到simple中 fread(simple,data5Length,1,in); fwrite(simple,data5Length,1,out); fclose(in); fclose(out); return 0;&#125; 分离各声道的数据：把各个声道的采集点数据分开存储。 12345678910111213141516171819202122232425/** * 将little-endian_2_44100_16.pcm 分离各声道的数据，即把各个声道的采集点数据分开存储。 */int separateLR(const char *url)&#123; FILE *in = fopen(url, &quot;rb+&quot;); FILE *outL = fopen(&quot;./output/l.pcm&quot;, &quot;wb+&quot;); FILE *outR = fopen(&quot;./output/r.pcm&quot;, &quot;wb+&quot;); int simpleLength = 16 / 8 * 2; char *simple = (char *)malloc(simpleLength); while (1)&#123; //每次从in文件中读取1组4个长度数据的到simple中 fread(simple,4,1,in); if(feof(in))&#123; break; &#125; //l(0声道)：1-2 fwrite(simple,2,1,outL); //r(1声道)：3-4 fwrite(simple+2,2,1,outR); &#125; fclose(in); fclose(outL); fclose(outR); return 0;&#125; 音量调节：把每个采集点数据的值 x 调节比例。注意：需要注意的是可调节范围，如：8位有无符号时最大是多少。 123456789101112131415161718192021222324252627282930313233343536373839/** * 将little-endian_2_44100_16.pcm 调节音量 比例 * 1、little-endian排序的值是如何排序的？真正的值是多少？ * 2、little-endian转成真正的值之后再进行计算，得到的结果再反转little-endian。 * 如：原始pcm数据：0xaa 0x01(左声道采样点数据)，当scale=2： * -&gt; 值：0x01aa * 2 = 0x0354 * -&gt; 转回little-endian再进行存储：0x5403（缩放后的值） */int volumeAdjustment(const char *url, float scale)&#123; FILE *in = fopen(url, &quot;rb+&quot;); FILE *out = fopen(&quot;./output/volume_adjustment.pcm&quot;, &quot;wb+&quot;); char *simple = (char *)malloc(4); while (1)&#123; //每次从in文件中读取1组4个长度数据的到simple中 fread(simple, 4, 1, in); if(feof(in))&#123; break; &#125; short *simple8bitTemp = (short *)malloc(2); //l(0声道)： simple8bitTemp[0] = (simple[0] + (simple[1] &lt;&lt; 8)) * scale; //r(1声道)： simple8bitTemp[1] = (simple[2] + (simple[3] &lt;&lt; 8)) * scale; simple[0] = simple8bitTemp[0] &amp; 0x00FF; simple[1] = simple8bitTemp[0] &gt;&gt; 8; simple[2] = simple8bitTemp[1] &amp; 0x00FF; simple[3] = simple8bitTemp[1] &gt;&gt; 8; for(int i=0; i&lt;4; i++)&#123; printf(&quot;simple[%d]=%d\\n&quot;,i,simple[i]); &#125; fwrite(simple, 4, 1, out); &#125; fclose(in); fclose(out); return 0;&#125; 播放速度：按照比例丢弃（或插入0）采集点的数据即可。（涉及到不是整数倍不单单是这么处理，我也不懂） 参照雷神的必看项目： 视音频数据处理入门：PCM音频采样数据处理 。 Android终端音频采样介绍 1、关于采集的主要api介绍 123456789101112/** * @param audioSource 音频来源&#123;@link MediaRecorder.AudioSource&#125;；如指定麦克风：MediaRecorder.AudioSource.MIC* @param sampleRateInHz 采样率&#123;@link AudioFormat#SAMPLE_RATE_UNSPECIFIED&#125;，单位Hz；安卓支持所有的设备是：44100Hz* @param channelConfig 声道数&#123;@link AudioFormat#CHANNEL_IN_MONO&#125;；* @param audioFormat 位宽&#123;@link AudioFormat#ENCODING_PCM_8BIT&#125;* @param bufferSizeInBytes 采集期间缓存区的大小*/public AudioRecord(int audioSource, int sampleRateInHz, int channelConfig, int audioFormat, int bufferSizeInBytes) //获取最小缓存区，参数跟AudioRecord保持一致int getMinBufferSize(int sampleRateInHz, int channelConfig, int audioFormat) &#123;&#125; 2、实现采集的伪代码 1234567891011121314151617181920212223242526//1、申请权限//2、获取最小缓存大小（根据api介绍，应该取要比预期大的缓冲区大小），这个大小其实也可以取①和②计算得来的大小int minBufferSize = AudioRecord.getMinBufferSize(44100, AudioFormat.CHANNEL_IN_STEREO, AudioFormat.ENCODING_PCM_16BIT) * 2;//3、初始化AudioRecord对象AudioRecord audioRecord = new AudioRecord(MediaRecorder.AudioSource.MIC, 44100, AudioFormat.CHANNEL_IN_STEREO, AudioFormat.ENCODING_PCM_16BIT, minBufferSize);//4、开始在子线程中进行采集数据new Thread(new Runnable() &#123; @Override public void run() &#123; audioRecord.startRecording(); while(isRunning)&#123; byte[] bytes = new byte[minBufferSize]; int len = audioRecord.read(bytes, 0, bytes.length); //这里就可以把数据直接写入到sdcard了，如：xxx.pcm；输出排序方式为：little endian。 &#125; //5、停止录音机 audioRecord.stop(); &#125;&#125;).start();//6、最后释放资源audioRecord.release(); 播放pcm原始数据 ffmpeg： ffplay -f s16le -sample_rate 44100 -channels 2 -i xxx.pcm 其他： Adobe Audition 参考 维基多媒体：pcm 视音频数据处理入门：PCM音频采样数据处理 Android 音视频开发_何俊林（书）","categories":[],"tags":[{"name":"直播推流全过程","slug":"直播推流全过程","permalink":"http://qincji.gitee.io/tags/%E7%9B%B4%E6%92%AD%E6%8E%A8%E6%B5%81%E5%85%A8%E8%BF%87%E7%A8%8B/"}]},{"title":"直播推流全过程：H.264描述符","slug":"rtmppush/h264-descriptor","date":"2020-12-04T04:50:20.000Z","updated":"2020-12-13T14:10:35.649Z","comments":true,"path":"2020/12/04/rtmppush/h264-descriptor/","link":"","permalink":"http://qincji.gitee.io/2020/12/04/rtmppush/h264-descriptor/","excerpt":"","text":"简述 H264/AVC文档中存在着大量元素描述符ue(v)，me(v)，se(v)，te(v)等，编码为ue(v)，me(v)，或者 se(v) 的语法元素是指数哥伦布编码，而编码为te(v)的语法元素是舍位指数哥伦布编码。这些语法元素的解析过程是由比特流当前位置比特开始读取，包括非0 比特，直至leading_bits 的数量为0。由于解码过程中需要计算出每个元素的占位(bit数量)，所以我们就不得不理解这些描述符了。 ue(v) 无符号整数指数哥伦布码编码的语法元素，左位在先。计算公式： ​ codeNum = 2 leadingZeroBits − 1 + read_bits( leadingZeroBits ) codeNum： 占的位数（bit数量） leadingZeroBits： 遇到第一个1前面0的个数；如：0010 1011，leadingZeroBits的值为2； read_bits( leadingZeroBits )： 遇到第一个1后面leadingZeroBits个组成的无符号二进制值；如：0010 1011，值为…0 1…，即01，即1； 举两个栗子： （1）0001 1001 =&gt;leadingZeroBits== 000. …= 3，read_bits( 3 )==… 100.=4，所以：codeNum=23-1+4=13 （2）0000 0101 0000 0000 =&gt; leadingZeroBits=5，read_bits( 5 ) = … …01 000. …=8，codeNum=25-1+8=39 se(v) 有符号整数指数哥伦布码编码的语法元素位在先。在按照上面ue(v)公式计算出codeNum后，然后使用该计算公式： value = (−1)k+1 Ceil( k÷2 ) Ceil： 返回大于或者等于指定表达式的最小整数，如： Ceil(1.5)= 2 如上例（1）0001 1001 =&gt; codeNum=23-1+4=13，value = (-1)13+1Ceil(13÷2)=Ceil(6.5)=7 me(v) 映射的指数哥伦布码编码的语法元素，左位在先。在按照上面ue(v)公式计算出codeNum后，然后查表。（在H.264-AVC-ISO_IEC_14496-10的9.1.2 章节中表9-4） te(v) 舍位指数哥伦布码编码语法元素，左位在先。明确取值范围在0-x；当x&gt;1时，te(v)就是ue(v)；否则(x=1)，b = read_bits( 1 )，codeNum = !b 其他 ae(v)： 上下文自适应算术熵编码语法元素 b(8)： 任意形式的8比特字节。 f(n)： n位固定模式比特串（由左至右），左位在先。 i(n)： 使用n比特的有符号整数。 u(n)： n位无符号整数。 参考 (1).H.264-AVC-ISO_IEC_14496-10 (2).https://blog.csdn.net/lizhijian21/article/details/80982403","categories":[],"tags":[{"name":"直播推流全过程","slug":"直播推流全过程","permalink":"http://qincji.gitee.io/tags/%E7%9B%B4%E6%92%AD%E6%8E%A8%E6%B5%81%E5%85%A8%E8%BF%87%E7%A8%8B/"}]},{"title":"直播推流全过程：视频数据源之YUV（1）","slug":"rtmppush/1-yuv","date":"2020-12-03T14:20:51.000Z","updated":"2020-12-08T14:04:24.293Z","comments":true,"path":"2020/12/03/rtmppush/1-yuv/","link":"","permalink":"http://qincji.gitee.io/2020/12/03/rtmppush/1-yuv/","excerpt":"","text":"视频基本概念 一个视频简单点理解就是播放一张张画面。我们就从这里面把视频的相关名词扯出来：①一张画面，一张画面也就一帧画面；属性为图像的大小或尺寸称分别率；画面的成像组成的方式有：rgb和yuv；跟计算器关联起来还不是用0101的比特来表示②当画面遇上了时间，爱的结晶就出来了：比特率、帧率和刷新率。接下来我们简单介绍一下他们的作用： 视频帧： 常见有I帧（关键帧，含完整画面，所以数据量大）、P帧（前向参考帧，参考前面I帧编码的图像信息）、B帧（双向预测帧，参考前面I帧、前面P帧和后面I帧编码的图像信息）；我们网上看视频时常常会遇到拖动进度条出现回退一两秒的情况吧？因为那个位置的当前帧不是I帧，没有完整的画面。 分辨率： 图像的大小或尺寸。 RGB： 任何彩色图像可由红绿蓝组成。RGB每一个通道占8位，1个字节内存。每个像素包含一个RGB，占3个字节（如果加上透明度RGBA则占32位，总共4个字节）。如：1920 x 1080内存大小=1920 x 1080 x 3=5.9M。 YUV(YCbCr)： Y：亮度；UV：色度和饱和度；wiki YCbCr 介绍。目前大多数都是使用yuv格式来表示视频帧的裸流数据。具体详情请往下阅读。 比特率(码率)： 单位时间内播放媒体（包括视频和音频）的比特数量（bit的数量）。文件大小计算公式： 文件大小（b）= 码率（b/s）x 时间（s） 帧率(帧数)： 画面每秒传输帧数，单位：fps（frame per second）或者 “赫兹”（Hz）。对于人眼感官常用范围在15~75fps之间。 刷新率： 屏幕在每秒刷新（画面）的次数。单位：赫兹（Hz）。 YUV基本介绍 人类视觉系统（HVS）对亮度比彩色更敏感，所以把Y和UV单独抽出来，每一个像素点都有一个Y，4个Y和一组UV（UV数量不定）共同绘制4个像素点，而Y和UV的比例不一样就分了多种 取样格式。 YUV与RGB的相互转化 RGB转YUV： Y = 0.299R + 0.587G + 0.114B U = 0.564(B - Y) V = 0.713(R - Y) YUV转RGB： R = Y + 1.402V B = Y + 1.772U G = Y - 0.344U - 0.714V YUV取样格式 常见的取样格式有以下3种 4：4：4 每4个素位置都有4个YUV，内存计算：1920 x 1080 = 1920 x 1080 x 3=5.9M； 4：2：2 每4个Y像素具有2个U和2个V；内存计算：1920 x 1080 = 1920 x 1080 x (1 + 2/4 + 2/4)=3.9M； 4：2：0 每4个Y像素具有1个U和1个V，使用在视频领域中应用最广泛。内存计算：1920 x 1080 = 1920 x 1080 x (1 + 1/4 + 1/4)=2.8M； YUV数据排列格式 在这里介绍两种格式，一种是Android平台特有NV21（又称YUV420SP），另一种则是其他大部分平台同样的I420（又称YUV420P），这两个取样格式都是4:2:0，所以说他们两种的数据完全一样，只是放到内存里面的顺序变了。（我们要实现把从Android采样NV21数据转成I420然后推送到服务器。） NV21： ①先把Y数据全部排序完；②UV数据交替排序完； I420： ①先把Y数据全部排序完；②U数据排序完；③V数据排序完； YUV初步实战 手写分离YUV分量以及对其进行播放 请前往 视音频数据处理入门：RGB、YUV像素数据处理 进行学习。对“前人种树，后人乘凉”感触颇深，只是太可惜了！ YUV数据源的采集（Android端） 12345678910111213141516171819202122//1.相机权限//2.获取相机，有后置摄像头：Camera.CameraInfo.CAMERA_FACING_BACK和前置摄像头：Camera.CameraInfo.CAMERA_FACING_FRONTCamera camera = Camera.open(cameraId);//3、Parameters这里封装着当前摄像头所能提供的参数（真实宽高等）Camera.Parameters parameters = camera.getParameters();//根据parameters.getSupportedPreviewSizes()提供的宽高尺寸挑选一个设置进去parameters.setPreviewSize(width, height);//设置预览数据为nv21（注意：仅仅是预览的数据，通过onPreviewFrame回调的仍没有发生变化）parameters.setPreviewFormat(ImageFormat.NV21);//设置预览角度，通过WindowManager.getDefaultDisplay().getRotation()参数查看。（因为android手机厂商安装摄像头传感器方向不统一，所以数据可能是旋转过的，所以要回正）camera.setDisplayOrientation(degrees);//设置修改过的数据，使得生效camera.setParameters(parameters);//4、设置数据监听，我们会在onPreviewFrame(byte[] data, Camera camera)处理回调的数据，这里的数据就是每一帧原始数据流。我们会先把数据按照角度回正（注意回正后的宽高可能是调换的），然后转成I420就行编码发送。camera.setPreviewCallbackWithBuffer(this);//5、启动预览画面camera.setPreviewDisplay(holder);camera.startPreview(); NV21数据旋转 比如NV21数据以及顺时针旋转90度后的对比： 实现顺时针和逆时针旋转90度的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** *yuv_n21_rotation(&quot;assets/yuv_nv21_800x480_back.yuv&quot;,800,480,90,&quot;output/out_nv21_480x800_back.yuv&quot;); * 从android摄像机获取到的nv21格式数据，进行旋转 */int yuv_n21_rotation(const char *url_in, int width, int height, int rotation, const char *url_out) &#123; FILE *pIn = fopen(url_in, &quot;rb+&quot;); FILE *pOut = fopen(url_out, &quot;wb+&quot;); int yuvSize = width * height * 3 / 2; unsigned char *simple = (unsigned char *) malloc(yuvSize); unsigned char *simpleOut = (unsigned char *) malloc(yuvSize); fread(simple, 1, yuvSize, pIn); //顺时针旋转90 if (rotation == 90) &#123; //宽高取反，把竖变行 int k = 0; //宽高取反，把竖变行 //y数据 for (int w = 0; w &lt; width; w++) &#123; for (int h = height - 1; h &gt;= 0; h--) &#123; simpleOut[k++] = simple[h * width + w]; &#125; &#125; //uv数据 height*width -&gt; 3/2height*width for (int w = 0; w &lt; width; w+=2) &#123; for (int h = height / 2 - 1; h &gt;= 0; h--) &#123;// *(simpleOut + k) = simple[width * height + h * width + w]; // u simpleOut[k++] = simple[width*height + width * h + w]; // v simpleOut[k++] = simple[width*height + width * h + w + 1]; &#125; &#125; &#125; else if(rotation == -90)&#123; //宽高取反，把竖变行 int k = 0; //宽高取反，把竖变行 //y数据 for (int w = width -1; w &gt;= 0; w--) &#123; for (int h = 0; h &lt; height; h++) &#123; simpleOut[k++] = simple[h * width + w]; &#125; &#125; //uv数据 height*width -&gt; 3/2height*width for (int w = 0; w &lt; width; w+=2) &#123; for (int h = height / 2 - 1; h &gt;= 0; h--) &#123;// *(simpleOut + k) = simple[width * height + h * width + w]; simpleOut[k++] = simple[width*height + width * h + w]; simpleOut[k++] = simple[width*height + width * h + w + 1]; &#125; &#125; &#125; fwrite(simpleOut, 1, yuvSize, pOut); return 0;&#125; NV21数据格式转I420数据格式 12345678910111213141516171819202122232425//nv21_to_i420(&quot;assets/yuv_nv21_800x480_back.yuv&quot;,800,480,&quot;output/out_yuv_i420_800x480_back.yuv&quot;);int nv21_to_i420(const char *url_in, int width, int height, const char *url_out)&#123; FILE *pIn = fopen(url_in, &quot;rb+&quot;); FILE *pOut = fopen(url_out, &quot;wb+&quot;); int ySize = width * height; int uvSize = ySize /2; int yuvSize = ySize * 3 / 2; unsigned char *simple = (unsigned char *) malloc(yuvSize); unsigned char *simpleOut = (unsigned char *) malloc(yuvSize); fread(simple,yuvSize,1,pIn); //y memcpy(simpleOut, simple, ySize); for (int i = 0; i &lt; uvSize/2; i++) &#123; //u *(simpleOut + ySize + i) = *(simple + ySize + i * 2); //v *(simpleOut + ySize + i + uvSize/2) = *(simple + ySize + i * 2 + 1); &#125; fwrite(simpleOut,yuvSize,1,pOut); fclose(pIn); fclose(pOut); return 0;&#125; 参考 wiki YCbCr 视音频数据处理入门：RGB、YUV像素数据处理 新一代视频压缩编码标准-H.264_AVC(第二版) （书） 音视频开发进阶指南：基于Android与iOS平台的实践（书） Android 音视频开发_何俊林（书）","categories":[],"tags":[{"name":"直播推流全过程","slug":"直播推流全过程","permalink":"http://qincji.gitee.io/tags/%E7%9B%B4%E6%92%AD%E6%8E%A8%E6%B5%81%E5%85%A8%E8%BF%87%E7%A8%8B/"}]}],"categories":[],"tags":[{"name":"ffmpeg","slug":"ffmpeg","permalink":"http://qincji.gitee.io/tags/ffmpeg/"},{"name":"其他","slug":"其他","permalink":"http://qincji.gitee.io/tags/%E5%85%B6%E4%BB%96/"},{"name":"直播推流全过程","slug":"直播推流全过程","permalink":"http://qincji.gitee.io/tags/%E7%9B%B4%E6%92%AD%E6%8E%A8%E6%B5%81%E5%85%A8%E8%BF%87%E7%A8%8B/"}]}